# Interrelationships & Modeling {#sec-modeling-relationships}

Move beyond simple group comparisons to understand relationships between variables and build predictive models.

::: {.callout-tip}
## Chapter Overview
This chapter builds upon the hypothesis testing methods from @sec-comparative-inference to explore relationships between variables. You'll learn correlation analysis, regression modeling, and crucial evaluation metrics like ROC curves and AUC. These concepts lead naturally to the specialized methods in @sec-specialized-methods.
:::

## Introduction

In biostatistics, we often need to understand relationships between variables and make predictions. This chapter covers fundamental techniques for exploring associations, building predictive models, and evaluating their performance in medical and biological contexts.

## Correlation Analysis

### Understanding Correlation

Correlation measures the strength and direction of a linear relationship between two continuous variables. In biostatistics and molecular biology, correlation analysis is fundamental for understanding biological relationships:

**Common biological correlations:**
- Gene expression levels between co-regulated genes
- Protein abundance and mRNA expression
- Tumor size and metastatic potential
- Drug concentration and treatment response
- Metabolite levels in biochemical pathways

### Types of Correlation

#### Pearson Correlation Coefficient

The **Pearson correlation coefficient** ($r$) measures linear relationships and ranges from -1 to +1:

$$r = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_i - \bar{x})^2 \sum_{i=1}^{n}(y_i - \bar{y})^2}}$$

**Interpretation:**
- $r = 1$: Perfect positive linear relationship
- $r = 0$: No linear relationship
- $r = -1$: Perfect negative linear relationship

::: {.callout-tip}
## Interpreting Correlation Strength in Biology
- **|r| < 0.3**: Weak correlation (may still be biologically meaningful)
- **0.3 ≤ |r| < 0.7**: Moderate correlation (often significant in biological systems)
- **|r| ≥ 0.7**: Strong correlation (rare in biology due to noise and complexity)
:::

#### Spearman Rank Correlation

The **Spearman correlation coefficient** ($\rho$) measures monotonic relationships (not necessarily linear):

$$\rho = 1 - \frac{6\sum d_i^2}{n(n^2-1)}$$

Where $d_i$ is the difference between ranks of corresponding values.

**When to use Spearman:**
- Non-linear but monotonic relationships
- Ordinal data
- Presence of outliers
- Non-normally distributed data

### Gene Expression Correlation Analysis

#### Example 1: Co-expression of Related Genes

```{r}
#| echo: true
#| eval: true
library(ggplot2)
library(corrplot)
library(dplyr)

# Simulate gene expression data for 5 genes across 100 samples
set.seed(456)
n_samples <- 100

# Gene 1: Master regulator
gene1 <- rnorm(n_samples, mean = 8, sd = 1.5)

# Gene 2: Strongly co-expressed with Gene 1 (same pathway)
gene2 <- 0.8 * gene1 + rnorm(n_samples, mean = 1, sd = 0.8)

# Gene 3: Moderately co-expressed with Gene 1
gene3 <- 0.5 * gene1 + rnorm(n_samples, mean = 2, sd = 1.2)

# Gene 4: Negatively correlated with Gene 1 (antagonistic pathway)
gene4 <- -0.6 * gene1 + rnorm(n_samples, mean = 10, sd = 1)

# Gene 5: Independent gene (different pathway)
gene5 <- rnorm(n_samples, mean = 6, sd = 1.8)

# Create expression matrix
expression_data <- data.frame(
  Sample_ID = paste0("Sample_", 1:n_samples),
  BRCA1 = gene1,      # DNA repair gene
  BRCA2 = gene2,      # Co-expressed DNA repair gene
  ATM = gene3,        # DNA damage checkpoint gene
  MYC = gene4,        # Oncogene (often dysregulated when DNA repair is high)
  GAPDH = gene5       # Housekeeping gene
)

# Calculate correlation matrix
cor_matrix <- cor(expression_data[, -1])  # Exclude Sample_ID
cor_pvalues <- cor.test(expression_data$BRCA1, expression_data$BRCA2)

print("Gene Expression Correlation Matrix:")
print(round(cor_matrix, 3))

# Visualize correlation matrix
corrplot(cor_matrix, method = "color", type = "upper",
         addCoef.col = "black", tl.col = "black", tl.srt = 45,
         title = "Gene Co-expression Network", mar = c(0,0,1,0))

# Detailed analysis of BRCA1-BRCA2 correlation
brca_cor <- cor.test(expression_data$BRCA1, expression_data$BRCA2,
                     method = "pearson")

cat("BRCA1-BRCA2 Correlation Analysis:\n")
cat("Pearson r =", round(brca_cor$estimate, 3), "\n")
cat("P-value =", format(brca_cor$p.value, scientific = TRUE), "\n")
cat("95% CI: [", round(brca_cor$conf.int[1], 3), ", ",
    round(brca_cor$conf.int[2], 3), "]\n")

# Scatter plot with biological interpretation
ggplot(expression_data, aes(x = BRCA1, y = BRCA2)) +
  geom_point(alpha = 0.6, color = "darkblue") +
  geom_smooth(method = "lm", color = "red", se = TRUE) +
  labs(
    title = "Co-expression of DNA Repair Genes BRCA1 and BRCA2",
    subtitle = paste("r =", round(brca_cor$estimate, 3),
                     ", p =", format(brca_cor$p.value, digits = 3)),
    x = "BRCA1 Expression (log2 FPKM)",
    y = "BRCA2 Expression (log2 FPKM)"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(size = 12, face = "bold"))
```

#### Example 2: Protein-mRNA Correlation Analysis

```{r}
#| echo: true
#| eval: true
# Simulate protein abundance vs mRNA expression data
set.seed(789)
n_genes <- 50

# mRNA expression levels (log2 scale)
mRNA_expression <- rnorm(n_genes, mean = 5, sd = 2)

# Protein abundance (correlated with mRNA but with noise)
# Translation efficiency varies between proteins
translation_efficiency <- runif(n_genes, min = 0.3, max = 0.8)
protein_abundance <- translation_efficiency * mRNA_expression +
                    rnorm(n_genes, mean = 0, sd = 0.8)

# Create dataset
proteomics_data <- data.frame(
  Gene = paste0("Gene_", 1:n_genes),
  mRNA = mRNA_expression,
  Protein = protein_abundance,
  Translation_Efficiency = translation_efficiency
)

# Calculate correlations
pearson_cor <- cor.test(proteomics_data$mRNA, proteomics_data$Protein)
spearman_cor <- cor.test(proteomics_data$mRNA, proteomics_data$Protein,
                        method = "spearman")

cat("mRNA-Protein Correlation Analysis:\n")
cat("Pearson r =", round(pearson_cor$estimate, 3),
    "(p =", format(pearson_cor$p.value, digits = 3), ")\n")
cat("Spearman ρ =", round(spearman_cor$estimate, 3),
    "(p =", format(spearman_cor$p.value, digits = 3), ")\n")

# Visualization
p1 <- ggplot(proteomics_data, aes(x = mRNA, y = Protein)) +
  geom_point(aes(color = Translation_Efficiency), size = 3, alpha = 0.7) +
  geom_smooth(method = "lm", color = "black", linetype = "dashed") +
  scale_color_gradient(low = "lightblue", high = "darkred",
                      name = "Translation\nEfficiency") +
  labs(
    title = "mRNA Expression vs Protein Abundance",
    subtitle = "Color indicates translation efficiency",
    x = "mRNA Expression (log2 FPKM)",
    y = "Protein Abundance (log2 intensity)"
  ) +
  theme_minimal()

print(p1)

# Identify outliers (genes with unusual mRNA-protein relationships)
proteomics_data$residuals <- residuals(lm(Protein ~ mRNA, data = proteomics_data))
proteomics_data$outlier <- abs(proteomics_data$residuals) > 2 * sd(proteomics_data$residuals)

cat("Potential post-transcriptional regulation candidates:\n")
outlier_genes <- proteomics_data[proteomics_data$outlier, ]
print(outlier_genes[, c("Gene", "mRNA", "Protein", "Translation_Efficiency")])
```

### Tumor Biology Correlation Examples

#### Example 3: Tumor Size and Metastatic Markers

```{r}
#| echo: true
#| eval: true
# Simulate tumor progression data
set.seed(101)
n_tumors <- 150

# Primary tumor characteristics
tumor_size <- rexp(n_tumors, rate = 0.5)  # Exponential distribution (realistic for tumor sizes)
tumor_grade <- sample(1:3, n_tumors, replace = TRUE, prob = c(0.4, 0.4, 0.2))

# Metastatic markers (higher in larger, higher-grade tumors)
# VEGF: Vascular endothelial growth factor
vegf_expression <- 2 + 0.3 * tumor_size + 0.5 * tumor_grade + rnorm(n_tumors, sd = 0.8)

# MMP9: Matrix metalloproteinase (invasion marker)
mmp9_expression <- 1.5 + 0.25 * tumor_size + 0.6 * tumor_grade + rnorm(n_tumors, sd = 0.6)

# Ki67: Proliferation marker
ki67_percentage <- 10 + 8 * tumor_size + 5 * tumor_grade + rnorm(n_tumors, sd = 8)
ki67_percentage <- pmax(0, pmin(100, ki67_percentage))  # Bound between 0-100%

# Create tumor dataset
tumor_data <- data.frame(
  Tumor_ID = paste0("T", sprintf("%03d", 1:n_tumors)),
  Size_cm = tumor_size,
  Grade = factor(tumor_grade, labels = c("Low", "Intermediate", "High")),
  VEGF = vegf_expression,
  MMP9 = mmp9_expression,
  Ki67_percent = ki67_percentage
)

# Correlation analysis
cor_vegf_size <- cor.test(tumor_data$Size_cm, tumor_data$VEGF)
cor_mmp9_size <- cor.test(tumor_data$Size_cm, tumor_data$MMP9)
cor_ki67_size <- cor.test(tumor_data$Size_cm, tumor_data$Ki67_percent)

cat("Tumor Size Correlation Analysis:\n")
cat("Size vs VEGF: r =", round(cor_vegf_size$estimate, 3),
    "(p =", format(cor_vegf_size$p.value, digits = 3), ")\n")
cat("Size vs MMP9: r =", round(cor_mmp9_size$estimate, 3),
    "(p =", format(cor_mmp9_size$p.value, digits = 3), ")\n")
cat("Size vs Ki67: r =", round(cor_ki67_size$estimate, 3),
    "(p =", format(cor_ki67_size$p.value, digits = 3), ")\n")

# Multi-panel visualization
library(patchwork)

p1 <- ggplot(tumor_data, aes(x = Size_cm, y = VEGF, color = Grade)) +
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE, color = "black") +
  scale_color_manual(values = c("green", "orange", "red")) +
  labs(title = "VEGF Expression vs Tumor Size",
       x = "Tumor Size (cm)", y = "VEGF Expression") +
  theme_minimal()

p2 <- ggplot(tumor_data, aes(x = Size_cm, y = MMP9, color = Grade)) +
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE, color = "black") +
  scale_color_manual(values = c("green", "orange", "red")) +
  labs(title = "MMP9 Expression vs Tumor Size",
       x = "Tumor Size (cm)", y = "MMP9 Expression") +
  theme_minimal()

p3 <- ggplot(tumor_data, aes(x = Size_cm, y = Ki67_percent, color = Grade)) +
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE, color = "black") +
  scale_color_manual(values = c("green", "orange", "red")) +
  labs(title = "Ki67 Proliferation vs Tumor Size",
       x = "Tumor Size (cm)", y = "Ki67 (%)") +
  theme_minimal()

# Combine plots
combined_plot <- (p1 | p2) / p3
print(combined_plot)

# Correlation matrix of all markers
marker_matrix <- tumor_data[, c("Size_cm", "VEGF", "MMP9", "Ki67_percent")]
colnames(marker_matrix) <- c("Size", "VEGF", "MMP9", "Ki67")
marker_cor <- cor(marker_matrix)

corrplot(marker_cor, method = "color", type = "upper",
         addCoef.col = "black", tl.col = "black",
         title = "Tumor Marker Correlation Matrix", mar = c(0,0,1,0))
```

### Advanced Correlation Techniques

#### Partial Correlation

**Partial correlation** measures the relationship between two variables while controlling for one or more confounding variables.

**Formula for partial correlation:**
$$r_{xy \cdot z} = \frac{r_{xy} - r_{xz}r_{yz}}{\sqrt{(1-r_{xz}^2)(1-r_{yz}^2)}}$$

```{r}
#| echo: true
#| eval: true
# Function to calculate partial correlation manually
partial_cor <- function(x, y, z) {
  # Calculate correlation between x and y, controlling for z
  rxy <- cor(x, y)
  rxz <- cor(x, z)
  ryz <- cor(y, z)

  # Partial correlation formula
  r_xy_z <- (rxy - rxz * ryz) / (sqrt(1 - rxz^2) * sqrt(1 - ryz^2))
  return(r_xy_z)
}

# Example: Gene expression controlling for cell cycle effects
# Many genes appear correlated simply because they're all affected by cell cycle

set.seed(112)
n_samples <- 80

# Cell cycle score (confounding variable)
cell_cycle_score <- rnorm(n_samples, mean = 50, sd = 15)

# Gene A: Affected by cell cycle + specific function
geneA <- 0.4 * cell_cycle_score + rnorm(n_samples, mean = 5, sd = 1.5)

# Gene B: Affected by cell cycle + specific function + some correlation with A
geneB <- 0.3 * cell_cycle_score + 0.2 * geneA + rnorm(n_samples, mean = 6, sd = 1.2)

# Gene C: Only affected by cell cycle (control)
geneC <- 0.5 * cell_cycle_score + rnorm(n_samples, mean = 4, sd = 1)

partial_cor_data <- data.frame(
  Sample = 1:n_samples,
  Cell_Cycle = cell_cycle_score,
  GeneA = geneA,
  GeneB = geneB,
  GeneC = geneC
)

# Calculate regular correlations
regular_cor_AB <- cor.test(partial_cor_data$GeneA, partial_cor_data$GeneB)
regular_cor_AC <- cor.test(partial_cor_data$GeneA, partial_cor_data$GeneC)

# Calculate partial correlations (controlling for cell cycle)
partial_cor_AB_val <- partial_cor(partial_cor_data$GeneA, partial_cor_data$GeneB,
                                  partial_cor_data$Cell_Cycle)
partial_cor_AC_val <- partial_cor(partial_cor_data$GeneA, partial_cor_data$GeneC,
                                  partial_cor_data$Cell_Cycle)

cat("Regular vs Partial Correlation Analysis:\n")
cat("================================\n")
cat("Gene A vs Gene B:\n")
cat("  Regular correlation: r =", round(regular_cor_AB$estimate, 3),
    "(p =", format(regular_cor_AB$p.value, digits = 3), ")\n")
cat("  Partial correlation: r =", round(partial_cor_AB_val, 3), "\n\n")

cat("Gene A vs Gene C:\n")
cat("  Regular correlation: r =", round(regular_cor_AC$estimate, 3),
    "(p =", format(regular_cor_AC$p.value, digits = 3), ")\n")
cat("  Partial correlation: r =", round(partial_cor_AC_val, 3), "\n")

# Visualization - Create scatter plot matrix manually
library(gridExtra)

p1 <- ggplot(partial_cor_data, aes(x = GeneA, y = GeneB)) +
  geom_point(alpha = 0.6) + geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Gene A vs Gene B") + theme_minimal()

p2 <- ggplot(partial_cor_data, aes(x = GeneA, y = GeneC)) +
  geom_point(alpha = 0.6) + geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Gene A vs Gene C") + theme_minimal()

p3 <- ggplot(partial_cor_data, aes(x = Cell_Cycle, y = GeneA)) +
  geom_point(alpha = 0.6) + geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Cell Cycle vs Gene A") + theme_minimal()

p4 <- ggplot(partial_cor_data, aes(x = Cell_Cycle, y = GeneB)) +
  geom_point(alpha = 0.6) + geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Cell Cycle vs Gene B") + theme_minimal()

grid.arrange(p1, p2, p3, p4, ncol = 2,
             top = "Gene Expression Relationships with Cell Cycle Control")
```

#### Network Correlation Analysis

```{r}
#| echo: true
#| eval: true
library(corrplot)

# Simulate pathway gene expression network
set.seed(234)
n_genes <- 20

# Create a pathway with hub genes and their targets
pathway_genes <- paste0("Gene_", LETTERS[1:n_genes])

# Simulate expression data with network structure
expression_matrix <- matrix(rnorm(n_genes * 100), nrow = n_genes, ncol = 100)
rownames(expression_matrix) <- pathway_genes

# Add correlations based on known pathway interactions
# Gene A is a master regulator
expression_matrix[1, ] <- rnorm(100, mean = 8, sd = 1.5)  # Gene A

# Genes B, C, D are direct targets of A
for(i in 2:4) {
  expression_matrix[i, ] <- 0.7 * expression_matrix[1, ] + rnorm(100, sd = 1)
}

# Genes E, F are targets of B
for(i in 5:6) {
  expression_matrix[i, ] <- 0.6 * expression_matrix[2, ] + rnorm(100, sd = 1.2)
}

# Calculate correlation matrix
gene_cor_matrix <- cor(t(expression_matrix))

# Visualize the correlation network using corrplot
corrplot(gene_cor_matrix, method = "color", type = "upper",
         order = "hclust", hclust.method = "ward.D2",
         addrect = 3, rect.col = "black", rect.lwd = 2,
         tl.col = "black", tl.srt = 45, tl.cex = 0.7,
         title = "Gene Co-expression Network in Biological Pathway",
         mar = c(0,0,2,0))

# Identify highly connected genes (hub genes)
cor_threshold <- 0.5
strong_connections <- rowSums(abs(gene_cor_matrix) > cor_threshold) - 1  # Subtract 1 for self-correlation

hub_genes <- data.frame(
  Gene = pathway_genes,
  Connections = strong_connections
) %>%
  arrange(desc(Connections)) %>%
  head(5)

cat("Top hub genes (most connections):\n")
print(hub_genes)

# Create a heatmap showing the most connected genes
library(pheatmap)

# Select top 10 most variable genes for cleaner visualization
top_genes <- names(sort(apply(expression_matrix, 1, var), decreasing = TRUE)[1:10])
subset_cor_matrix <- gene_cor_matrix[top_genes, top_genes]

pheatmap(subset_cor_matrix,
         color = colorRampPalette(c("blue", "white", "red"))(50),
         breaks = seq(-1, 1, length.out = 51),
         display_numbers = TRUE,
         number_format = "%.2f",
         fontsize_number = 8,
         main = "Gene Co-expression Heatmap (Top Variable Genes)",
         cluster_rows = TRUE,
         cluster_cols = TRUE)
```

::: {.callout-note}
## Key Points for Biological Correlation Analysis

1. **Effect sizes matter more than p-values** in large datasets
2. **Partial correlation** helps identify direct vs indirect relationships
3. **Multiple testing correction** is crucial for genome-wide analyses
4. **Network analysis** reveals pathway-level organization
5. **Biological interpretation** should guide statistical significance thresholds
6. **Confounding variables** (batch effects, cell cycle, etc.) must be considered
:::

### Association Analysis Beyond Correlation

#### Chi-square Test for Categorical Associations

For categorical variables (e.g., mutation status, tumor type, treatment response):

$$\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i}$$

Where $O_i$ is observed frequency and $E_i$ is expected frequency.

```{r}
#| echo: true
#| eval: true
# Example: Association between gene mutation and cancer subtype
set.seed(456)
n_patients <- 200

# Simulate cancer subtypes
cancer_subtype <- sample(c("Luminal A", "Luminal B", "HER2+", "Triple Negative"),
                        n_patients, prob = c(0.4, 0.2, 0.15, 0.25), replace = TRUE)

# Simulate TP53 mutation status (higher in aggressive subtypes)
mutation_probs <- ifelse(cancer_subtype %in% c("HER2+", "Triple Negative"), 0.7, 0.2)
tp53_mutation <- rbinom(n_patients, 1, mutation_probs)

# Create contingency table
contingency_table <- table(cancer_subtype, tp53_mutation)
colnames(contingency_table) <- c("TP53 Wild-type", "TP53 Mutated")

print("Contingency Table: Cancer Subtype vs TP53 Mutation")
print(contingency_table)

# Chi-square test
chi_test <- chisq.test(contingency_table)
print(chi_test)

# Effect size (Cramér's V)
cramers_v <- sqrt(chi_test$statistic / (n_patients * (min(nrow(contingency_table),
                  ncol(contingency_table)) - 1)))
cat("Cramér's V =", round(cramers_v, 3), "\n")

# Visualization
library(ggplot2)
association_data <- data.frame(
  Subtype = cancer_subtype,
  TP53_Status = factor(tp53_mutation, labels = c("Wild-type", "Mutated"))
)

ggplot(association_data, aes(x = Subtype, fill = TP53_Status)) +
  geom_bar(position = "fill") +
  scale_fill_manual(values = c("lightblue", "darkred")) +
  labs(title = "TP53 Mutation Frequency by Cancer Subtype",
       y = "Proportion", x = "Cancer Subtype", fill = "TP53 Status") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Chi-squared Goodness of Fit Test in Biology

### Understanding Goodness of Fit

The **chi-squared goodness of fit test** determines whether observed data follows a specific expected distribution or theoretical model. In biology, this test is essential for:

- Testing Hardy-Weinberg equilibrium in population genetics
- Validating Mendelian inheritance patterns
- Assessing whether gene expression follows specific distributions
- Testing model assumptions in biological data
- Validating theoretical predictions against experimental observations

### Mathematical Foundation

The chi-squared goodness of fit statistic is:

$$\chi^2 = \sum_{i=1}^{k} \frac{(O_i - E_i)^2}{E_i}$$

Where:
- $O_i$ = Observed frequency in category $i$
- $E_i$ = Expected frequency in category $i$ under the null hypothesis
- $k$ = Number of categories
- Degrees of freedom = $k - 1 - p$ (where $p$ is the number of estimated parameters)

**Assumptions:**
1. Data are frequencies or counts (not proportions)
2. Categories are mutually exclusive and exhaustive
3. Expected frequency in each category ≥ 5
4. Observations are independent

### Hardy-Weinberg Equilibrium Testing

#### Example 1: Single Gene Analysis

The Hardy-Weinberg principle states that allele frequencies remain constant in a population under specific conditions. For a gene with two alleles (A and a) with frequencies $p$ and $q$:

**Expected genotype frequencies:**
- AA: $p^2$
- Aa: $2pq$
- aa: $q^2$

```{r}
#| echo: true
#| eval: true
# Example: Testing Hardy-Weinberg equilibrium for a disease susceptibility gene
library(ggplot2)
library(dplyr)

# Simulate population genetics data
set.seed(1234)
n_individuals <- 1000

# True allele frequencies
p_A <- 0.3  # Frequency of A allele (protective)
q_a <- 0.7  # Frequency of a allele (risk)

# Simulate genotypes under Hardy-Weinberg equilibrium
# Then add slight deviation to make it realistic
hw_probs <- c(p_A^2, 2*p_A*q_a, q_a^2)  # AA, Aa, aa
names(hw_probs) <- c("AA", "Aa", "aa")

# Observed genotypes (with slight deviation from HWE)
observed_counts <- c(
  AA = 85,   # Expected: p² × 1000 = 90
  Aa = 435,  # Expected: 2pq × 1000 = 420
  aa = 480   # Expected: q² × 1000 = 490
)

# Calculate expected counts under Hardy-Weinberg
total_individuals <- sum(observed_counts)
expected_counts <- hw_probs * total_individuals

# Estimate allele frequencies from observed data
total_alleles <- 2 * total_individuals
freq_A_observed <- (2 * observed_counts["AA"] + observed_counts["Aa"]) / total_alleles
freq_a_observed <- 1 - freq_A_observed

cat("Population Genetics Analysis:\n")
cat("============================\n")
cat("Sample size:", total_individuals, "individuals\n")
cat("Observed allele frequencies:\n")
cat("  A allele:", round(freq_A_observed, 3), "\n")
cat("  a allele:", round(freq_a_observed, 3), "\n\n")

# Expected counts under HWE using observed allele frequencies
expected_HWE <- c(
  AA = freq_A_observed^2 * total_individuals,
  Aa = 2 * freq_A_observed * freq_a_observed * total_individuals,
  aa = freq_a_observed^2 * total_individuals
)

# Chi-squared goodness of fit test
hwe_test <- chisq.test(observed_counts, p = expected_HWE/sum(expected_HWE))

cat("Hardy-Weinberg Equilibrium Test:\n")
cat("Observed vs Expected genotype counts:\n")
comparison_table <- data.frame(
  Genotype = names(observed_counts),
  Observed = observed_counts,
  Expected_HWE = round(expected_HWE, 1),
  Difference = observed_counts - expected_HWE
)
print(comparison_table)

cat("\nChi-squared test results:\n")
cat("Chi-squared =", round(hwe_test$statistic, 3), "\n")
cat("df =", hwe_test$parameter, "\n")
cat("p-value =", format(hwe_test$p.value, scientific = TRUE), "\n")

if(hwe_test$p.value < 0.05) {
  cat("Conclusion: Population deviates significantly from Hardy-Weinberg equilibrium\n")
} else {
  cat("Conclusion: Population is in Hardy-Weinberg equilibrium\n")
}

# Visualization
hw_data <- data.frame(
  Genotype = factor(rep(names(observed_counts), 2), levels = c("AA", "Aa", "aa")),
  Count = c(observed_counts, expected_HWE),
  Type = rep(c("Observed", "Expected (HWE)"), each = 3)
)

ggplot(hw_data, aes(x = Genotype, y = Count, fill = Type)) +
  geom_col(position = "dodge", alpha = 0.7) +
  scale_fill_manual(values = c("steelblue", "orange")) +
  labs(title = "Hardy-Weinberg Equilibrium Test",
       subtitle = paste("χ² =", round(hwe_test$statistic, 2),
                        ", p =", format(hwe_test$p.value, digits = 3)),
       x = "Genotype", y = "Count") +
  theme_minimal() +
  geom_text(aes(label = round(Count, 0)), position = position_dodge(width = 0.9),
            vjust = -0.3, size = 3)
```

#### Example 2: Multiple Alleles System

```{r}
#| echo: true
#| eval: true
# Example: ABO blood group system (multiple alleles)
# Alleles: A, B, O with frequencies p, q, r
# Genotypes: AA, AO (Type A), BB, BO (Type B), AB (Type AB), OO (Type O)

set.seed(5678)

# Population data for ABO blood groups
observed_phenotypes <- c(
  TypeA = 420,   # AA + AO genotypes
  TypeB = 280,   # BB + BO genotypes
  TypeAB = 110,  # AB genotype
  TypeO = 190    # OO genotype
)

total_n <- sum(observed_phenotypes)

# Estimate allele frequencies using maximum likelihood
# For ABO system: p + q + r = 1, where p=freq(A), q=freq(B), r=freq(O)
# Type O frequency = r², so r = sqrt(freq_O)
r_freq <- sqrt(observed_phenotypes["TypeO"] / total_n)

# Type A + Type O = (p + r)², so p + r = sqrt(freq_A + freq_O)
freq_A_O <- (observed_phenotypes["TypeA"] + observed_phenotypes["TypeO"]) / total_n
p_plus_r <- sqrt(freq_A_O)
p_freq <- p_plus_r - r_freq

# Type B + Type O = (q + r)², so q + r = sqrt(freq_B + freq_O)
freq_B_O <- (observed_phenotypes["TypeB"] + observed_phenotypes["TypeO"]) / total_n
q_plus_r <- sqrt(freq_B_O)
q_freq <- q_plus_r - r_freq

cat("ABO Blood Group Analysis:\n")
cat("=========================\n")
cat("Estimated allele frequencies:\n")
cat("A allele (p):", round(p_freq, 3), "\n")
cat("B allele (q):", round(q_freq, 3), "\n")
cat("O allele (r):", round(r_freq, 3), "\n")
cat("Sum:", round(p_freq + q_freq + r_freq, 3), "\n\n")

# Expected phenotype frequencies under HWE
expected_phenotypes <- c(
  TypeA = (p_freq^2 + 2*p_freq*r_freq) * total_n,    # AA + AO
  TypeB = (q_freq^2 + 2*q_freq*r_freq) * total_n,    # BB + BO
  TypeAB = (2*p_freq*q_freq) * total_n,               # AB
  TypeO = (r_freq^2) * total_n                        # OO
)

# Chi-squared goodness of fit test
abo_test <- chisq.test(observed_phenotypes, p = expected_phenotypes/sum(expected_phenotypes))

cat("Observed vs Expected phenotype counts:\n")
abo_comparison <- data.frame(
  Blood_Type = names(observed_phenotypes),
  Observed = observed_phenotypes,
  Expected = round(expected_phenotypes, 1),
  Residual = round((observed_phenotypes - expected_phenotypes), 1)
)
print(abo_comparison)

cat("\nChi-squared goodness of fit test:\n")
cat("Chi-squared =", round(abo_test$statistic, 3), "\n")
cat("df =", abo_test$parameter, "\n")
cat("p-value =", format(abo_test$p.value, digits = 4), "\n")

# Visualization
abo_data <- data.frame(
  Blood_Type = factor(rep(names(observed_phenotypes), 2)),
  Count = c(observed_phenotypes, expected_phenotypes),
  Type = rep(c("Observed", "Expected"), each = 4)
)

ggplot(abo_data, aes(x = Blood_Type, y = Count, fill = Type)) +
  geom_col(position = "dodge", alpha = 0.7) +
  scale_fill_manual(values = c("darkred", "lightcoral")) +
  labs(title = "ABO Blood Group Distribution",
       subtitle = "Testing Hardy-Weinberg Equilibrium",
       x = "Blood Type", y = "Count") +
  theme_minimal()
```

### Mendelian Inheritance Pattern Testing

#### Example 3: Testing Classical Mendelian Ratios

```{r}
#| echo: true
#| eval: true
# Example: F2 generation cross testing 9:3:3:1 ratio
# Dihybrid cross: AaBb × AaBb
# Expected ratio: 9 A_B_ : 3 A_bb : 3 aaB_ : 1 aabb

set.seed(9999)

# Simulated F2 generation data
observed_F2 <- c(
  Purple_Round = 315,    # A_B_ (dominant for both traits)
  Purple_Wrinkled = 108, # A_bb (dominant for trait A, recessive for B)
  Yellow_Round = 101,    # aaB_ (recessive for A, dominant for B)
  Yellow_Wrinkled = 32   # aabb (recessive for both traits)
)

total_offspring <- sum(observed_F2)

# Expected Mendelian ratio: 9:3:3:1
mendelian_ratio <- c(9, 3, 3, 1)
expected_F2 <- (mendelian_ratio / sum(mendelian_ratio)) * total_offspring

cat("Dihybrid Cross Analysis (F2 Generation):\n")
cat("=======================================\n")
cat("Total offspring:", total_offspring, "\n\n")

# Chi-squared test for Mendelian inheritance
mendelian_test <- chisq.test(observed_F2, p = expected_F2/sum(expected_F2))

cat("Testing 9:3:3:1 Mendelian ratio:\n")
mendel_comparison <- data.frame(
  Phenotype = names(observed_F2),
  Observed = observed_F2,
  Expected_931 = round(expected_F2, 1),
  Ratio_Observed = round(observed_F2 / min(observed_F2), 2),
  Ratio_Expected = mendelian_ratio
)
print(mendel_comparison)

cat("\nChi-squared goodness of fit test:\n")
cat("Chi-squared =", round(mendelian_test$statistic, 3), "\n")
cat("df =", mendelian_test$parameter, "\n")
cat("p-value =", format(mendelian_test$p.value, digits = 4), "\n")

if(mendelian_test$p.value > 0.05) {
  cat("Conclusion: Data consistent with 9:3:3:1 Mendelian ratio\n")
} else {
  cat("Conclusion: Data deviates significantly from expected Mendelian ratio\n")
}

# Calculate individual chi-squared contributions
chi_contributions <- (observed_F2 - expected_F2)^2 / expected_F2
cat("\nContribution to chi-squared by phenotype:\n")
for(i in 1:length(chi_contributions)) {
  cat(names(chi_contributions)[i], ":", round(chi_contributions[i], 3), "\n")
}

# Visualization
mendel_data <- data.frame(
  Phenotype = factor(rep(names(observed_F2), 2)),
  Count = c(observed_F2, expected_F2),
  Type = rep(c("Observed", "Expected (9:3:3:1)"), each = 4)
)

ggplot(mendel_data, aes(x = Phenotype, y = Count, fill = Type)) +
  geom_col(position = "dodge", alpha = 0.7) +
  scale_fill_manual(values = c("darkgreen", "lightgreen")) +
  labs(title = "Dihybrid Cross: Testing Mendelian Inheritance",
       subtitle = paste("χ² =", round(mendelian_test$statistic, 2),
                        ", p =", format(mendelian_test$p.value, digits = 3)),
       x = "Phenotype", y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Distribution Fitting in Biology

#### Example 4: Testing Gene Expression Distribution

```{r}
#| echo: true
#| eval: true
# Example: Testing if gene expression follows a normal distribution
library(fitdistrplus)

set.seed(2468)

# Simulate gene expression data (log-transformed FPKM values)
# True distribution is slightly skewed (log-normal)
n_genes <- 500
true_expression <- rlnorm(n_genes, meanlog = 2, sdlog = 0.8)
log_expression <- log2(true_expression)

# Test normality using chi-squared goodness of fit
# First, create bins for the continuous data
n_bins <- 8
expression_breaks <- quantile(log_expression, probs = seq(0, 1, length.out = n_bins + 1))
observed_counts <- table(cut(log_expression, breaks = expression_breaks, include.lowest = TRUE))

# Estimate normal distribution parameters
mean_expr <- mean(log_expression)
sd_expr <- sd(log_expression)

# Calculate expected frequencies under normal distribution
bin_probs <- numeric(n_bins)
for(i in 1:n_bins) {
  lower <- expression_breaks[i]
  upper <- expression_breaks[i + 1]
  bin_probs[i] <- pnorm(upper, mean_expr, sd_expr) - pnorm(lower, mean_expr, sd_expr)
}

expected_counts <- bin_probs * n_genes

cat("Gene Expression Distribution Analysis:\n")
cat("====================================\n")
cat("Sample size:", n_genes, "genes\n")
cat("Mean expression:", round(mean_expr, 2), "log2(FPKM)\n")
cat("SD expression:", round(sd_expr, 2), "log2(FPKM)\n\n")

# Chi-squared goodness of fit test for normality
# df = number of bins - 1 - number of estimated parameters (2 for normal: mean, sd)
normality_test <- chisq.test(as.numeric(observed_counts), p = bin_probs)

cat("Testing normality of gene expression:\n")
norm_comparison <- data.frame(
  Bin = 1:n_bins,
  Range = paste0("(", round(expression_breaks[1:n_bins], 1), ", ",
                round(expression_breaks[2:(n_bins+1)], 1), "]"),
  Observed = as.numeric(observed_counts),
  Expected = round(expected_counts, 1)
)
print(norm_comparison)

cat("\nChi-squared goodness of fit test:\n")
cat("Chi-squared =", round(normality_test$statistic, 3), "\n")
cat("df =", normality_test$parameter, "\n")
cat("p-value =", format(normality_test$p.value, digits = 4), "\n")

# Alternative: Shapiro-Wilk test for comparison (for smaller samples)
if(n_genes <= 5000) {
  shapiro_test <- shapiro.test(log_expression)
  cat("\nShapiro-Wilk test (for comparison):\n")
  cat("W =", round(shapiro_test$statistic, 4), "\n")
  cat("p-value =", format(shapiro_test$p.value, digits = 4), "\n")
}

# Visualization: Q-Q plot and histogram
library(patchwork)

# Q-Q plot
qq_data <- data.frame(
  Theoretical = qnorm(ppoints(n_genes)),
  Sample = sort(scale(log_expression)[, 1])
)

p1 <- ggplot(qq_data, aes(x = Theoretical, y = Sample)) +
  geom_point(alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Q-Q Plot: Testing Normality",
       x = "Theoretical Quantiles", y = "Sample Quantiles") +
  theme_minimal()

# Histogram with normal overlay
p2 <- ggplot(data.frame(expression = log_expression), aes(x = expression)) +
  geom_histogram(aes(y = ..density..), bins = 20, alpha = 0.7, fill = "skyblue") +
  stat_function(fun = dnorm, args = list(mean = mean_expr, sd = sd_expr),
                color = "red", size = 1, linetype = "dashed") +
  labs(title = "Gene Expression Distribution",
       subtitle = "Blue: Observed, Red: Normal distribution",
       x = "log2(FPKM)", y = "Density") +
  theme_minimal()

print(p1 | p2)

# Test for other distributions
cat("\nTesting alternative distributions:\n")

# Log-normal test (on original scale)
original_data <- 2^log_expression
lnorm_fit <- fitdist(original_data, "lnorm")
lnorm_gof <- gofstat(lnorm_fit)
cat("Log-normal distribution:\n")
cat("  Anderson-Darling A² =", round(lnorm_gof$ad, 3), "\n")
cat("  Kolmogorov-Smirnov D =", round(lnorm_gof$ks, 3), "\n")

# Gamma distribution test
gamma_fit <- fitdist(original_data, "gamma")
gamma_gof <- gofstat(gamma_fit)
cat("Gamma distribution:\n")
cat("  Anderson-Darling A² =", round(gamma_gof$ad, 3), "\n")
cat("  Kolmogorov-Smirnov D =", round(gamma_gof$ks, 3), "\n")
```

#### Example 5: Mutation Rate Distribution

```{r}
#| echo: true
#| eval: true
# Example: Testing if mutations follow a Poisson distribution
set.seed(3579)

# Simulate mutation count data across genomic regions
n_regions <- 200
mean_mutations <- 2.5

# Generate data with slight overdispersion (negative binomial)
# But test against Poisson assumption
observed_mutations <- rnbinom(n_regions, size = 10, mu = mean_mutations)

# Create frequency table
mutation_counts <- table(observed_mutations)
max_mutations <- max(observed_mutations)

# Expected frequencies under Poisson distribution
lambda_est <- mean(observed_mutations)
expected_poisson <- dpois(0:max_mutations, lambda_est) * n_regions

# Match observed and expected for chi-squared test
observed_freq <- numeric(max_mutations + 1)
names(observed_freq) <- 0:max_mutations

for(i in names(mutation_counts)) {
  observed_freq[i] <- mutation_counts[i]
}

# Combine rare categories (expected < 5) for valid chi-squared test
combine_threshold <- 5
last_valid_category <- max_mutations

for(i in max_mutations:0) {
  if(expected_poisson[i + 1] < combine_threshold) {
    last_valid_category <- i - 1
  } else {
    break
  }
}

if(last_valid_category < max_mutations) {
  # Combine categories with expected < 5
  observed_combined <- observed_freq[1:(last_valid_category + 1)]
  observed_combined[length(observed_combined)] <- sum(observed_freq[(last_valid_category + 1):length(observed_freq)])

  expected_combined <- expected_poisson[1:(last_valid_category + 1)]
  expected_combined[length(expected_combined)] <- sum(expected_poisson[(last_valid_category + 1):length(expected_poisson)])

  category_names <- c(0:last_valid_category, paste0(last_valid_category + 1, "+"))
} else {
  observed_combined <- observed_freq
  expected_combined <- expected_poisson
  category_names <- 0:max_mutations
}

cat("Mutation Distribution Analysis:\n")
cat("==============================\n")
cat("Sample size:", n_regions, "genomic regions\n")
cat("Mean mutations per region:", round(lambda_est, 2), "\n")
cat("Variance:", round(var(observed_mutations), 2), "\n")
cat("Variance-to-mean ratio:", round(var(observed_mutations)/mean(observed_mutations), 2), "\n")
cat("(Poisson: ratio = 1, Overdispersed: ratio > 1)\n\n")

# Chi-squared goodness of fit test
poisson_test <- chisq.test(observed_combined, p = expected_combined/sum(expected_combined))

cat("Testing Poisson distribution:\n")
poisson_comparison <- data.frame(
  Mutations = category_names,
  Observed = observed_combined,
  Expected_Poisson = round(expected_combined, 1),
  Deviation = round(observed_combined - expected_combined, 1)
)
print(poisson_comparison)

cat("\nChi-squared goodness of fit test:\n")
cat("Chi-squared =", round(poisson_test$statistic, 3), "\n")
cat("df =", poisson_test$parameter, "\n")
cat("p-value =", format(poisson_test$p.value, digits = 4), "\n")

if(poisson_test$p.value > 0.05) {
  cat("Conclusion: Mutation counts consistent with Poisson distribution\n")
} else {
  cat("Conclusion: Mutation counts deviate from Poisson distribution\n")
  cat("Consider: Negative binomial (overdispersion) or zero-inflated models\n")
}

# Visualization
mutation_data <- data.frame(
  Mutations = factor(rep(category_names, 2)),
  Count = c(observed_combined, expected_combined),
  Type = rep(c("Observed", "Expected (Poisson)"), each = length(category_names))
)

ggplot(mutation_data, aes(x = Mutations, y = Count, fill = Type)) +
  geom_col(position = "dodge", alpha = 0.7) +
  scale_fill_manual(values = c("purple", "gold")) +
  labs(title = "Mutation Count Distribution",
       subtitle = paste("Testing Poisson model (λ =", round(lambda_est, 2), ")"),
       x = "Number of Mutations", y = "Frequency") +
  theme_minimal()

# Additional overdispersion test
cat("\nOverdispersion test:\n")
if(var(observed_mutations) > mean(observed_mutations) * 1.2) {
  cat("Evidence of overdispersion - consider negative binomial model\n")

  # Fit negative binomial for comparison
  library(MASS)
  nb_params <- fitdistr(observed_mutations, "negative binomial")
  cat("Negative binomial parameters:\n")
  cat("  size =", round(nb_params$estimate["size"], 2), "\n")
  cat("  mu =", round(nb_params$estimate["mu"], 2), "\n")
} else {
  cat("No strong evidence of overdispersion\n")
}
```

### Model Adequacy Testing

#### Example 6: Testing Regression Model Assumptions

```{r}
#| echo: true
#| eval: true
# Example: Testing normality of residuals in biological regression
set.seed(4680)

# Simulate dose-response data with non-normal errors
n_doses <- 60
drug_dose <- rep(c(0, 1, 2, 5, 10, 20), each = 10)

# True response with slight heteroscedasticity
true_response <- 10 + 3 * log(drug_dose + 1) + rnorm(n_doses, sd = 0.5 + 0.1 * drug_dose)

dose_response_data <- data.frame(
  Dose = drug_dose,
  Response = true_response
)

# Fit linear regression model
response_model <- lm(Response ~ log(Dose + 1), data = dose_response_data)
summary(response_model)

# Extract residuals
residuals_data <- data.frame(
  Fitted = fitted(response_model),
  Residuals = residuals(response_model),
  Standardized_Residuals = rstandard(response_model)
)

# Test normality of residuals using chi-squared
n_bins_resid <- 6
residual_breaks <- quantile(residuals_data$Standardized_Residuals,
                           probs = seq(0, 1, length.out = n_bins_resid + 1))
observed_resid_counts <- table(cut(residuals_data$Standardized_Residuals,
                                  breaks = residual_breaks, include.lowest = TRUE))

# Expected frequencies under standard normal
resid_bin_probs <- numeric(n_bins_resid)
for(i in 1:n_bins_resid) {
  lower <- residual_breaks[i]
  upper <- residual_breaks[i + 1]
  resid_bin_probs[i] <- pnorm(upper) - pnorm(lower)
}

expected_resid_counts <- resid_bin_probs * n_doses

# Chi-squared test for residual normality
residual_normality_test <- chisq.test(as.numeric(observed_resid_counts),
                                     p = resid_bin_probs)

cat("Regression Model Diagnostics:\n")
cat("============================\n")
cat("Testing normality of standardized residuals:\n")

resid_comparison <- data.frame(
  Bin = 1:n_bins_resid,
  Observed = as.numeric(observed_resid_counts),
  Expected = round(expected_resid_counts, 1)
)
print(resid_comparison)

cat("\nChi-squared test for residual normality:\n")
cat("Chi-squared =", round(residual_normality_test$statistic, 3), "\n")
cat("df =", residual_normality_test$parameter, "\n")
cat("p-value =", format(residual_normality_test$p.value, digits = 4), "\n")

# Diagnostic plots
library(patchwork)

p1 <- ggplot(residuals_data, aes(x = Fitted, y = Residuals)) +
  geom_point(alpha = 0.7) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_smooth(se = FALSE, color = "blue") +
  labs(title = "Residuals vs Fitted Values",
       x = "Fitted Values", y = "Residuals") +
  theme_minimal()

p2 <- ggplot(residuals_data, aes(sample = Standardized_Residuals)) +
  geom_qq() +
  geom_qq_line(color = "red", linetype = "dashed") +
  labs(title = "Q-Q Plot of Standardized Residuals",
       x = "Theoretical Quantiles", y = "Sample Quantiles") +
  theme_minimal()

print(p1 | p2)

# Additional tests
cat("\nAdditional normality tests:\n")
if(n_doses <= 5000) {
  shapiro_resid <- shapiro.test(residuals_data$Standardized_Residuals)
  cat("Shapiro-Wilk test: W =", round(shapiro_resid$statistic, 4),
      ", p =", format(shapiro_resid$p.value, digits = 4), "\n")
}

# Test for heteroscedasticity
library(car)
bp_test <- ncvTest(response_model)
cat("Breusch-Pagan test for heteroscedasticity:\n")
cat("Chi-squared =", round(bp_test$ChiSquare, 3),
    ", p =", format(bp_test$p, digits = 4), "\n")

# Recommendations based on test results
cat("\nModel adequacy assessment:\n")
if(residual_normality_test$p.value < 0.05) {
  cat("- Residuals deviate from normality - consider transformations\n")
} else {
  cat("- Residuals approximately normal\n")
}

if(bp_test$p < 0.05) {
  cat("- Evidence of heteroscedasticity - consider weighted regression\n")
} else {
  cat("- Homoscedasticity assumption satisfied\n")
}
```

::: {.callout-warning}
## Important Considerations for Chi-squared Goodness of Fit Tests

1. **Sample size requirements**: Expected frequency ≥ 5 in each category
2. **Parameter estimation**: Degrees of freedom = categories - 1 - estimated parameters
3. **Binning continuous data**: Choice of bins can affect results
4. **Multiple testing**: Correct for multiple comparisons when testing many distributions
5. **Biological interpretation**: Statistical significance doesn't always imply biological significance
6. **Alternative tests**: Consider Kolmogorov-Smirnov, Anderson-Darling for continuous data
:::

::: {.callout-note}
## Key Applications in Biology

1. **Population genetics**: Hardy-Weinberg equilibrium, linkage disequilibrium
2. **Inheritance patterns**: Mendelian ratios, segregation distortion
3. **Distribution modeling**: Gene expression, mutation rates, species abundance
4. **Model validation**: Checking assumptions in regression, ANOVA
5. **Quality control**: Experimental design validation, batch effect detection
6. **Evolutionary biology**: Neutral theory testing, selection detection
:::

### Python Implementation

```{python}
#| echo: true
#| eval: true
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import chi2

# Hardy-Weinberg equilibrium test
def hardy_weinberg_test(genotype_counts, alpha=0.05):
    """
    Test Hardy-Weinberg equilibrium for a single gene with two alleles

    Parameters:
    genotype_counts: dict with keys 'AA', 'Aa', 'aa' and their counts
    alpha: significance level

    Returns:
    dict with test results
    """
    # Calculate total individuals and allele frequencies
    total = sum(genotype_counts.values())

    # Estimate allele frequencies
    freq_A = (2 * genotype_counts['AA'] + genotype_counts['Aa']) / (2 * total)
    freq_a = 1 - freq_A

    # Expected genotype frequencies under HWE
    expected_counts = {
        'AA': freq_A**2 * total,
        'Aa': 2 * freq_A * freq_a * total,
        'aa': freq_a**2 * total
    }

    # Chi-squared test
    observed = list(genotype_counts.values())
    expected = list(expected_counts.values())

    chi2_stat = sum((o - e)**2 / e for o, e in zip(observed, expected))
    df = len(observed) - 1 - 1  # -1 for estimated parameter (allele freq)
    p_value = 1 - chi2.cdf(chi2_stat, df)

    return {
        'chi2_statistic': chi2_stat,
        'degrees_of_freedom': df,
        'p_value': p_value,
        'freq_A': freq_A,
        'freq_a': freq_a,
        'expected_counts': expected_counts,
        'significant': p_value < alpha
    }

# Example usage
genotype_data = {'AA': 85, 'Aa': 435, 'aa': 480}
hwe_result = hardy_weinberg_test(genotype_data)

print("Hardy-Weinberg Equilibrium Test Results:")
print(f"Chi-squared: {hwe_result['chi2_statistic']:.3f}")
print(f"p-value: {hwe_result['p_value']:.6f}")
print(f"A allele frequency: {hwe_result['freq_A']:.3f}")
print(f"a allele frequency: {hwe_result['freq_a']:.3f}")

# Mendelian ratio test
def mendelian_ratio_test(observed_counts, expected_ratio, alpha=0.05):
    """
    Test observed counts against expected Mendelian ratio

    Parameters:
    observed_counts: list of observed counts
    expected_ratio: list of expected ratios (e.g., [9, 3, 3, 1])
    alpha: significance level

    Returns:
    dict with test results
    """
    total_observed = sum(observed_counts)

    # Calculate expected counts
    total_ratio = sum(expected_ratio)
    expected_counts = [(r / total_ratio) * total_observed for r in expected_ratio]

    # Chi-squared test
    chi2_stat = sum((o - e)**2 / e for o, e in zip(observed_counts, expected_counts))
    df = len(observed_counts) - 1
    p_value = 1 - chi2.cdf(chi2_stat, df)

    return {
        'chi2_statistic': chi2_stat,
        'degrees_of_freedom': df,
        'p_value': p_value,
        'expected_counts': expected_counts,
        'observed_ratio': [o / min(observed_counts) for o in observed_counts],
        'significant': p_value < alpha
    }

# Example: Test 9:3:3:1 ratio
f2_data = [315, 108, 101, 32]
mendelian_result = mendelian_ratio_test(f2_data, [9, 3, 3, 1])

print("\nMendelian Ratio Test (9:3:3:1):")
print(f"Chi-squared: {mendelian_result['chi2_statistic']:.3f}")
print(f"p-value: {mendelian_result['p_value']:.6f}")
print(f"Observed ratio: {[round(r, 1) for r in mendelian_result['observed_ratio']]}")

# Visualization
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

# HWE plot
genotypes = list(genotype_data.keys())
observed_hwe = list(genotype_data.values())
expected_hwe = list(hwe_result['expected_counts'].values())

x = np.arange(len(genotypes))
width = 0.35

ax1.bar(x - width/2, observed_hwe, width, label='Observed', alpha=0.7)
ax1.bar(x + width/2, expected_hwe, width, label='Expected (HWE)', alpha=0.7)
ax1.set_xlabel('Genotype')
ax1.set_ylabel('Count')
ax1.set_title('Hardy-Weinberg Equilibrium Test')
ax1.set_xticks(x)
ax1.set_xticklabels(genotypes)
ax1.legend()

# Mendelian ratio plot
phenotypes = ['Purple Round', 'Purple Wrinkled', 'Yellow Round', 'Yellow Wrinkled']
observed_mendel = f2_data
expected_mendel = mendelian_result['expected_counts']

x = np.arange(len(phenotypes))
ax2.bar(x - width/2, observed_mendel, width, label='Observed', alpha=0.7)
ax2.bar(x + width/2, expected_mendel, width, label='Expected (9:3:3:1)', alpha=0.7)
ax2.set_xlabel('Phenotype')
ax2.set_ylabel('Count')
ax2.set_title('Mendelian Inheritance Test')
ax2.set_xticks(x)
ax2.set_xticklabels(phenotypes, rotation=45)
ax2.legend()

plt.tight_layout()
plt.show()
```

## Linear Regression in Biological Research

### The Linear Model

Linear regression models the relationship between predictor variables and an outcome, fundamental for understanding biological dose-response relationships, gene regulation, and biomarker associations.

#### Simple Linear Regression

$$Y_i = \beta_0 + \beta_1 X_i + \epsilon_i$$

Where:
- $\beta_0$: Intercept (baseline level when X = 0)
- $\beta_1$: Slope (change in Y per unit change in X)
- $\epsilon_i$: Random error term (biological variation)

### Gene Expression Dose-Response Example

#### Example 1: Drug Concentration vs Gene Expression

```{r}
#| echo: true
#| eval: true
# Simulate drug treatment experiment
library(ggplot2)
library(broom)

set.seed(567)
n_treatments <- 60

# Drug concentrations (μM)
drug_concentration <- rep(c(0, 0.1, 0.5, 1, 5, 10), each = 10)

# Target gene expression response (log2 fold change)
# Includes biological variation and experimental noise
baseline_expression <- 0
max_response <- 3.5
ic50 <- 2  # Half-maximal concentration

# Hill equation for dose-response (common in pharmacology)
theoretical_response <- baseline_expression +
  (max_response * drug_concentration) / (ic50 + drug_concentration)

# Add biological variation
observed_expression <- theoretical_response + rnorm(n_treatments, sd = 0.4)

# Create dataset
drug_response_data <- data.frame(
  Treatment_ID = 1:n_treatments,
  Concentration_uM = drug_concentration,
  Gene_Expression_FC = observed_expression,
  log_Concentration = log10(drug_concentration + 0.01)  # Add small constant for log
)

# Fit linear regression
linear_model <- lm(Gene_Expression_FC ~ Concentration_uM, data = drug_response_data)
log_model <- lm(Gene_Expression_FC ~ log_Concentration, data = drug_response_data)

# Model summaries
summary(linear_model)
summary(log_model)

# Extract key statistics
linear_stats <- glance(linear_model)
log_stats <- glance(log_model)

cat("Model Comparison:\n")
cat("Linear model R² =", round(linear_stats$r.squared, 3), "\n")
cat("Log model R² =", round(log_stats$r.squared, 3), "\n")

# Visualization
p1 <- ggplot(drug_response_data, aes(x = Concentration_uM, y = Gene_Expression_FC)) +
  geom_point(alpha = 0.7, size = 3, color = "steelblue") +
  geom_smooth(method = "lm", color = "red", linetype = "dashed") +
  labs(title = "Linear Model: Gene Expression vs Drug Concentration",
       x = "Drug Concentration (μM)", y = "Gene Expression (log2 FC)") +
  theme_minimal()

p2 <- ggplot(drug_response_data, aes(x = log_Concentration, y = Gene_Expression_FC)) +
  geom_point(alpha = 0.7, size = 3, color = "darkgreen") +
  geom_smooth(method = "lm", color = "red", linetype = "dashed") +
  labs(title = "Log Model: Gene Expression vs log(Concentration)",
       x = "log10(Concentration + 0.01)", y = "Gene Expression (log2 FC)") +
  theme_minimal()

library(patchwork)
print(p1 / p2)

# Residual analysis
residual_data <- data.frame(
  Fitted = fitted(linear_model),
  Residuals = residuals(linear_model),
  Concentration = drug_response_data$Concentration_uM
)

ggplot(residual_data, aes(x = Fitted, y = Residuals)) +
  geom_point(alpha = 0.7) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  geom_smooth(se = FALSE, color = "blue") +
  labs(title = "Residual Plot: Linear Model",
       x = "Fitted Values", y = "Residuals") +
  theme_minimal()
```

#### Example 2: Tumor Size Prediction from Biomarkers

```{r}
#| echo: true
#| eval: true
# Simulate tumor biomarker data
set.seed(678)
n_tumors <- 100

# Tumor characteristics
tumor_age_weeks <- runif(n_tumors, min = 2, max = 20)  # Tumor age
vascularization_score <- rnorm(n_tumors, mean = 5, sd = 1.5)  # 1-10 scale

# Tumor volume (cm³) - depends on age and vascularization
# Exponential growth modified by vascularization
base_growth_rate <- 0.15
volume <- exp(base_growth_rate * tumor_age_weeks +
              0.1 * vascularization_score +
              rnorm(n_tumors, sd = 0.3))

# Log-transform for linear modeling
log_volume <- log(volume)

tumor_growth_data <- data.frame(
  Tumor_ID = paste0("Tumor_", 1:n_tumors),
  Age_weeks = tumor_age_weeks,
  Vascularization = vascularization_score,
  Volume_cm3 = volume,
  log_Volume = log_volume
)

# Multiple regression model
growth_model <- lm(log_Volume ~ Age_weeks + Vascularization, data = tumor_growth_data)
summary(growth_model)

# Extract coefficients with confidence intervals
coef_summary <- tidy(growth_model, conf.int = TRUE)
print(coef_summary)

# Biological interpretation
cat("Biological Interpretation:\n")
cat("Growth rate: Volume increases by", round((exp(coef_summary$estimate[2]) - 1) * 100, 1),
    "% per week\n")
cat("Vascularization effect: Each unit increase in vascularization score\n")
cat("  increases volume by", round((exp(coef_summary$estimate[3]) - 1) * 100, 1), "%\n")

# Model diagnostics
par(mfrow = c(2, 2))
plot(growth_model)
par(mfrow = c(1, 1))

# Prediction example
new_tumor <- data.frame(
  Age_weeks = c(8, 12, 16),
  Vascularization = c(4, 6, 8)
)

predictions <- predict(growth_model, new_tumor, interval = "prediction")
pred_volume <- exp(predictions)  # Back-transform from log scale

prediction_results <- data.frame(
  Age_weeks = new_tumor$Age_weeks,
  Vascularization = new_tumor$Vascularization,
  Predicted_Volume = pred_volume[, "fit"],
  Lower_CI = pred_volume[, "lwr"],
  Upper_CI = pred_volume[, "upr"]
)

print("Tumor Volume Predictions:")
print(round(prediction_results, 2))
```

### Multiple Linear Regression

#### Example 3: Gene Expression Prediction from Multiple Factors

```{r}
#| echo: true
#| eval: true
# Simulate comprehensive gene regulation study
set.seed(789)
n_samples <- 120

# Regulatory factors
transcription_factor_A <- rnorm(n_samples, mean = 6, sd = 1.2)  # TF-A expression
chromatin_accessibility <- runif(n_samples, min = 0.2, max = 1.0)  # ATAC-seq score
dna_methylation <- rbeta(n_samples, 2, 5)  # Beta distribution for methylation
histone_h3k4me3 <- rgamma(n_samples, shape = 3, scale = 1.5)  # Activating histone mark

# Target gene expression (multiple regulatory inputs)
target_gene_expression <-
  2.0 +                                    # Baseline
  0.8 * transcription_factor_A +           # TF binding effect
  3.0 * chromatin_accessibility +          # Chromatin accessibility
  -2.5 * dna_methylation +                 # Methylation repression
  0.4 * histone_h3k4me3 +                  # Histone activation
  0.3 * transcription_factor_A * chromatin_accessibility +  # Interaction
  rnorm(n_samples, sd = 0.8)              # Biological noise

gene_regulation_data <- data.frame(
  Sample_ID = paste0("Sample_", 1:n_samples),
  TF_A_expression = transcription_factor_A,
  Chromatin_access = chromatin_accessibility,
  DNA_methylation = dna_methylation,
  H3K4me3_signal = histone_h3k4me3,
  Target_gene = target_gene_expression
)

# Fit multiple regression models
# Model 1: Main effects only
model_main <- lm(Target_gene ~ TF_A_expression + Chromatin_access +
                 DNA_methylation + H3K4me3_signal,
                 data = gene_regulation_data)

# Model 2: Include interaction
model_interaction <- lm(Target_gene ~ TF_A_expression + Chromatin_access +
                       DNA_methylation + H3K4me3_signal +
                       TF_A_expression:Chromatin_access,
                       data = gene_regulation_data)

# Compare models
anova(model_main, model_interaction)
summary(model_interaction)

# Calculate standardized coefficients (beta coefficients)
library(car)
standardized_coefs <- data.frame(
  Variable = names(coef(model_interaction))[-1],  # Exclude intercept
  Standardized_Beta = scale(model.matrix(model_interaction)[, -1]) %*%
                     coef(model_interaction)[-1] / sd(gene_regulation_data$Target_gene)
)

cat("Standardized coefficients (relative importance):\n")
print(standardized_coefs[order(-abs(standardized_coefs$Standardized_Beta)), ])

# Model performance metrics
model_performance <- data.frame(
  Model = c("Main Effects", "With Interaction"),
  R_squared = c(summary(model_main)$r.squared, summary(model_interaction)$r.squared),
  Adj_R_squared = c(summary(model_main)$adj.r.squared, summary(model_interaction)$adj.r.squared),
  AIC = c(AIC(model_main), AIC(model_interaction)),
  BIC = c(BIC(model_main), BIC(model_interaction))
)

print("Model Comparison:")
print(round(model_performance, 3))

# Visualization of key relationships
p1 <- ggplot(gene_regulation_data, aes(x = TF_A_expression, y = Target_gene,
                                      color = Chromatin_access)) +
  geom_point(alpha = 0.7) +
  scale_color_gradient(low = "red", high = "blue", name = "Chromatin\nAccess") +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  labs(title = "TF-A vs Target Gene (colored by chromatin accessibility)",
       x = "TF-A Expression", y = "Target Gene Expression") +
  theme_minimal()

p2 <- ggplot(gene_regulation_data, aes(x = DNA_methylation, y = Target_gene)) +
  geom_point(alpha = 0.7, color = "darkred") +
  geom_smooth(method = "lm", color = "black") +
  labs(title = "DNA Methylation vs Target Gene",
       x = "DNA Methylation Level", y = "Target Gene Expression") +
  theme_minimal()

print(p1 / p2)

# Interaction plot
library(interactions)
interact_plot(model_interaction, pred = TF_A_expression, modx = Chromatin_access,
             plot.points = TRUE, point.alpha = 0.5,
             main.title = "TF-A × Chromatin Accessibility Interaction")
```

### Regression Assumptions and Diagnostics

#### Checking Model Assumptions in Biological Data

```{r}
#| echo: true
#| eval: true
library(performance)
library(see)

# Comprehensive model diagnostics
check_model(model_interaction)

# Individual assumption checks
cat("Linearity Check:\n")
check_linearity(model_interaction)

cat("\nHomoscedasticity Check:\n")
check_heteroscedasticity(model_interaction)

cat("\nNormality of Residuals:\n")
check_normality(model_interaction)

cat("\nCollinearity Check:\n")
check_collinearity(model_interaction)

# Outlier detection
outliers <- check_outliers(model_interaction)
print(outliers)

# Cook's distance for influential points
cooks_d <- cooks.distance(model_interaction)
influential_samples <- which(cooks_d > 4/n_samples)

if(length(influential_samples) > 0) {
  cat("Influential samples (high Cook's distance):\n")
  print(gene_regulation_data[influential_samples, c("Sample_ID", "Target_gene")])
}
```

### Advanced Regression Techniques

#### Robust Regression for Outlier-Resistant Analysis

```{r}
#| echo: true
#| eval: true
library(MASS)

# Fit robust regression (less sensitive to outliers)
robust_model <- rlm(Target_gene ~ TF_A_expression + Chromatin_access +
                   DNA_methylation + H3K4me3_signal,
                   data = gene_regulation_data)

# Compare standard vs robust regression
comparison_coefs <- data.frame(
  Variable = names(coef(model_main)),
  Standard_LM = coef(model_main),
  Robust_LM = coef(robust_model),
  Difference = coef(model_main) - coef(robust_model)
)

print("Standard vs Robust Regression Coefficients:")
print(round(comparison_coefs, 3))

# Identify samples with different weights in robust regression
sample_weights <- robust_model$w
low_weight_samples <- which(sample_weights < 0.8)

cat("Samples with reduced weight in robust regression (potential outliers):\n")
if(length(low_weight_samples) > 0) {
  print(gene_regulation_data[low_weight_samples,
                            c("Sample_ID", "Target_gene", "TF_A_expression")])
}
```

## Logistic Regression for Classification

### When to Use Logistic Regression

Logistic regression is essential for binary classification problems in biology:
- Disease diagnosis (positive/negative)
- Treatment response (responder/non-responder)
- Gene function prediction (essential/non-essential)
- Tumor classification (malignant/benign)
- Survival outcomes (survived/died)

### The Logistic Model

Instead of predicting the outcome directly, logistic regression predicts the log-odds:

$$\text{logit}(p) = \ln\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_k X_k$$

Where $p$ is the probability of the event occurring.

The probability is then:

$$p = \frac{e^{\beta_0 + \beta_1 X_1 + ... + \beta_k X_k}}{1 + e^{\beta_0 + \beta_1 X_1 + ... + \beta_k X_k}}$$

### Tumor Classification Examples

#### Example 1: Malignant vs Benign Tumor Classification

```{r}
#| echo: true
#| eval: true
# Simulate tumor classification data
library(ggplot2)
library(pROC)
library(caret)

set.seed(890)
n_tumors <- 300

# Tumor characteristics
tumor_size <- rexp(n_tumors, rate = 1.5)  # Exponential distribution
cell_density <- rnorm(n_tumors, mean = 1000, sd = 300)  # cells per mm²
vascularity_score <- rgamma(n_tumors, shape = 2, scale = 3)  # 0-15 scale
ki67_index <- rbeta(n_tumors, 2, 8) * 100  # 0-100% proliferation
nuclear_atypia <- sample(1:4, n_tumors, replace = TRUE, prob = c(0.4, 0.3, 0.2, 0.1))

# Create malignancy probability based on biological factors
logit_malignant <- -3 +
  0.8 * tumor_size +                    # Larger tumors more likely malignant
  0.002 * cell_density +                # Higher density increases risk
  0.15 * vascularity_score +            # High vascularity suspicious
  0.04 * ki67_index +                   # High proliferation index
  0.6 * nuclear_atypia                  # Nuclear atypia strongly predictive

prob_malignant <- plogis(logit_malignant)  # Convert to probability
malignant <- rbinom(n_tumors, 1, prob_malignant)

# Create dataset
tumor_classification_data <- data.frame(
  Tumor_ID = paste0("T", sprintf("%03d", 1:n_tumors)),
  Size_cm = tumor_size,
  Cell_Density = cell_density,
  Vascularity = vascularity_score,
  Ki67_Index = ki67_index,
  Nuclear_Atypia = factor(nuclear_atypia, labels = c("None", "Mild", "Moderate", "Severe")),
  Malignant = factor(malignant, labels = c("Benign", "Malignant"))
)

# Fit logistic regression model
malignancy_model <- glm(Malignant ~ Size_cm + Cell_Density + Vascularity +
                       Ki67_Index + Nuclear_Atypia,
                       family = binomial, data = tumor_classification_data)

summary(malignancy_model)

# Calculate odds ratios with confidence intervals
odds_ratios <- exp(cbind(coef(malignancy_model), confint(malignancy_model)))
colnames(odds_ratios) <- c("Odds_Ratio", "CI_Lower", "CI_Upper")

cat("Odds Ratios and 95% Confidence Intervals:\n")
print(round(odds_ratios, 3))

# Model predictions
tumor_classification_data$predicted_prob <- predict(malignancy_model, type = "response")
tumor_classification_data$predicted_class <- ifelse(tumor_classification_data$predicted_prob > 0.5,
                                                   "Malignant", "Benign")

# Model performance evaluation
conf_matrix <- confusionMatrix(
  factor(tumor_classification_data$predicted_class, levels = c("Benign", "Malignant")),
  tumor_classification_data$Malignant
)

print(conf_matrix)

# ROC curve analysis
roc_curve <- roc(malignant, tumor_classification_data$predicted_prob)
auc_value <- auc(roc_curve)

cat("AUC =", round(auc_value, 3), "\n")

# Plot ROC curve
ggroc(roc_curve, color = "blue", size = 1) +
  geom_abline(intercept = 1, slope = 1, linetype = "dashed", color = "red") +
  labs(title = paste("ROC Curve: Tumor Malignancy Classification (AUC =", round(auc_value, 3), ")"),
       x = "1 - Specificity (False Positive Rate)",
       y = "Sensitivity (True Positive Rate)") +
  theme_minimal()

# Feature importance visualization
coef_data <- data.frame(
  Feature = names(coef(malignancy_model))[-1],  # Exclude intercept
  Coefficient = coef(malignancy_model)[-1],
  Odds_Ratio = exp(coef(malignancy_model)[-1])
)

ggplot(coef_data, aes(x = reorder(Feature, Coefficient), y = Coefficient)) +
  geom_col(fill = "steelblue", alpha = 0.7) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  coord_flip() +
  labs(title = "Logistic Regression Coefficients",
       subtitle = "Positive coefficients increase malignancy probability",
       x = "Features", y = "Coefficient") +
  theme_minimal()
```

#### Example 2: Gene Expression-Based Cancer Subtype Classification

```{r}
#| echo: true
#| eval: true
# Simulate gene expression-based cancer classification
set.seed(991)
n_patients <- 250

# Simulate expression of key cancer genes
# ER (Estrogen Receptor) - high in hormone-positive cancers
er_expression <- c(rnorm(125, mean = 8, sd = 1.2),    # High ER group
                   rnorm(125, mean = 3, sd = 1.0))    # Low ER group

# HER2 - amplified in ~20% of breast cancers
her2_amplified <- sample(c(0, 1), n_patients, replace = TRUE, prob = c(0.8, 0.2))
her2_expression <- ifelse(her2_amplified, rnorm(sum(her2_amplified), 9, 1),
                         rnorm(n_patients - sum(her2_amplified), 4, 1))

# TP53 mutation signature (composite score)
tp53_signature <- rnorm(n_patients, mean = 5, sd = 1.5)

# Proliferation signature (cell cycle genes)
prolif_signature <- rgamma(n_patients, shape = 3, scale = 2)

# Immune signature
immune_signature <- rbeta(n_patients, 2, 2) * 10

# Define cancer subtypes based on expression patterns
# Luminal A: ER+, HER2-, low proliferation
# Luminal B: ER+, HER2+/-, high proliferation
# HER2+: ER-, HER2+
# Triple Negative: ER-, HER2-, often high TP53 signature

subtype_prob_lumA <- plogis(-2 + 0.8 * er_expression - 2 * her2_amplified - 0.3 * prolif_signature)
subtype_prob_lumB <- plogis(-3 + 0.6 * er_expression + 0.5 * prolif_signature)
subtype_prob_her2 <- plogis(-4 + 3 * her2_amplified - 0.5 * er_expression)

# Assign subtypes (simplified logic)
cancer_subtype <- character(n_patients)
for(i in 1:n_patients) {
  probs <- c(subtype_prob_lumA[i], subtype_prob_lumB[i], subtype_prob_her2[i])
  if(er_expression[i] > 6 & her2_amplified[i] == 0 & prolif_signature[i] < 4) {
    cancer_subtype[i] <- "Luminal_A"
  } else if(er_expression[i] > 6 & prolif_signature[i] >= 4) {
    cancer_subtype[i] <- "Luminal_B"
  } else if(her2_amplified[i] == 1) {
    cancer_subtype[i] <- "HER2_Positive"
  } else {
    cancer_subtype[i] <- "Triple_Negative"
  }
}

# Create gene expression dataset
gene_expression_data <- data.frame(
  Patient_ID = paste0("P", sprintf("%03d", 1:n_patients)),
  ER_Expression = er_expression,
  HER2_Expression = her2_expression,
  HER2_Amplified = factor(her2_amplified),
  TP53_Signature = tp53_signature,
  Proliferation_Signature = prolif_signature,
  Immune_Signature = immune_signature,
  Cancer_Subtype = factor(cancer_subtype)
)

# Split data for training and testing
set.seed(123)
train_indices <- createDataPartition(gene_expression_data$Cancer_Subtype, p = 0.7, list = FALSE)
train_data <- gene_expression_data[train_indices, ]
test_data <- gene_expression_data[-train_indices, ]

# Train multinomial logistic regression for multi-class classification
library(nnet)
multinomial_model <- multinom(Cancer_Subtype ~ ER_Expression + HER2_Expression +
                             TP53_Signature + Proliferation_Signature + Immune_Signature,
                             data = train_data, trace = FALSE)

summary(multinomial_model)

# Make predictions
train_predictions <- predict(multinomial_model, train_data)
test_predictions <- predict(multinomial_model, test_data)

# Training performance
train_confusion <- confusionMatrix(train_predictions, train_data$Cancer_Subtype)
print("Training Set Performance:")
print(train_confusion)

# Test performance
test_confusion <- confusionMatrix(test_predictions, test_data$Cancer_Subtype)
print("Test Set Performance:")
print(test_confusion)

# Prediction probabilities for each class
test_probs <- predict(multinomial_model, test_data, type = "probs")
test_data_with_probs <- cbind(test_data, test_probs)

# Visualize prediction confidence
library(reshape2)
prob_data <- melt(test_data_with_probs[, c("Patient_ID", "Cancer_Subtype",
                                          "Luminal_A", "Luminal_B", "HER2_Positive", "Triple_Negative")],
                 id.vars = c("Patient_ID", "Cancer_Subtype"),
                 variable.name = "Predicted_Subtype", value.name = "Probability")

ggplot(prob_data, aes(x = Cancer_Subtype, y = Probability, fill = Predicted_Subtype)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~ Predicted_Subtype, nrow = 2) +
  labs(title = "Prediction Probabilities by True Cancer Subtype",
       x = "True Subtype", y = "Predicted Probability") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Advanced Classification Techniques

#### Example 3: Random Forest for Gene Expression Classification

```{r}
#| echo: true
#| eval: true
library(randomForest)
library(ROCR)

# Train Random Forest model for comparison
rf_model <- randomForest(Cancer_Subtype ~ ER_Expression + HER2_Expression +
                        TP53_Signature + Proliferation_Signature + Immune_Signature,
                        data = train_data, ntree = 500, importance = TRUE)

print(rf_model)

# Variable importance
importance_scores <- importance(rf_model)
importance_df <- data.frame(
  Gene = rownames(importance_scores),
  Mean_Decrease_Accuracy = importance_scores[, "MeanDecreaseAccuracy"],
  Mean_Decrease_Gini = importance_scores[, "MeanDecreaseGini"]
)

ggplot(importance_df, aes(x = reorder(Gene, Mean_Decrease_Accuracy),
                         y = Mean_Decrease_Accuracy)) +
  geom_col(fill = "darkgreen", alpha = 0.7) +
  coord_flip() +
  labs(title = "Gene Importance in Cancer Subtype Classification",
       x = "Genes", y = "Mean Decrease in Accuracy") +
  theme_minimal()

# Random Forest predictions
rf_test_predictions <- predict(rf_model, test_data)
rf_test_confusion <- confusionMatrix(rf_test_predictions, test_data$Cancer_Subtype)

print("Random Forest Test Performance:")
print(rf_test_confusion)

# Compare model performances
model_comparison <- data.frame(
  Model = c("Multinomial Logistic", "Random Forest"),
  Accuracy = c(test_confusion$overall["Accuracy"],
               rf_test_confusion$overall["Accuracy"]),
  Kappa = c(test_confusion$overall["Kappa"],
            rf_test_confusion$overall["Kappa"])
)

print("Model Comparison:")
print(round(model_comparison, 3))
```

### Biomarker Discovery and Validation

#### Example 4: Protein Biomarker Panel for Early Cancer Detection

```{r}
#| echo: true
#| eval: true
# Simulate protein biomarker discovery study
set.seed(1001)
n_controls <- 150
n_cases <- 100

# Simulate protein abundance levels (log-transformed)
# 10 proteins measured, 3 are true biomarkers

# Control samples
control_proteins <- matrix(rnorm(n_controls * 10, mean = 5, sd = 1),
                          nrow = n_controls, ncol = 10)

# Case samples - biomarkers 1, 3, 7 are elevated
case_proteins <- matrix(rnorm(n_cases * 10, mean = 5, sd = 1),
                       nrow = n_cases, ncol = 10)

# Add signal to true biomarkers
case_proteins[, 1] <- rnorm(n_cases, mean = 6.5, sd = 1.2)  # Protein 1: strong signal
case_proteins[, 3] <- rnorm(n_cases, mean = 6.0, sd = 1.1)  # Protein 3: moderate signal
case_proteins[, 7] <- rnorm(n_cases, mean = 5.8, sd = 1.0)  # Protein 7: weak signal

# Combine data
all_proteins <- rbind(control_proteins, case_proteins)
cancer_status <- c(rep(0, n_controls), rep(1, n_cases))

protein_names <- paste0("Protein_", LETTERS[1:10])
colnames(all_proteins) <- protein_names

biomarker_data <- data.frame(
  Sample_ID = paste0("S", sprintf("%03d", 1:(n_controls + n_cases))),
  Cancer = factor(cancer_status, labels = c("Control", "Cancer")),
  all_proteins
)

# Split into discovery and validation sets
discovery_indices <- sample(1:nrow(biomarker_data), size = 0.6 * nrow(biomarker_data))
discovery_set <- biomarker_data[discovery_indices, ]
validation_set <- biomarker_data[-discovery_indices, ]

# Univariate analysis to identify candidate biomarkers
univariate_results <- data.frame(
  Protein = protein_names,
  AUC = numeric(10),
  P_value = numeric(10)
)

for(i in 1:10) {
  protein_col <- paste0("Protein_", LETTERS[i])

  # Logistic regression
  model <- glm(Cancer ~ get(protein_col), data = discovery_set, family = binomial)
  p_val <- summary(model)$coefficients[2, 4]

  # ROC analysis
  roc_obj <- roc(discovery_set$Cancer, discovery_set[[protein_col]])
  auc_val <- as.numeric(auc(roc_obj))

  univariate_results[i, "AUC"] <- auc_val
  univariate_results[i, "P_value"] <- p_val
}

# Adjust p-values for multiple testing
univariate_results$Adj_P_value <- p.adjust(univariate_results$P_value, method = "BH")

cat("Univariate Biomarker Analysis (Discovery Set):\n")
print(univariate_results[order(-univariate_results$AUC), ])

# Select top biomarkers for panel (AUC > 0.7 and adj p < 0.05)
selected_biomarkers <- univariate_results[
  univariate_results$AUC > 0.7 & univariate_results$Adj_P_value < 0.05, "Protein"
]

cat("Selected biomarkers for panel:", paste(selected_biomarkers, collapse = ", "), "\n")

# Build multivariate model with selected biomarkers
panel_formula <- as.formula(paste("Cancer ~", paste(selected_biomarkers, collapse = " + ")))
panel_model <- glm(panel_formula, data = discovery_set, family = binomial)

summary(panel_model)

# Validate panel performance
# Discovery set performance
discovery_probs <- predict(panel_model, discovery_set, type = "response")
discovery_roc <- roc(discovery_set$Cancer, discovery_probs)

# Validation set performance
validation_probs <- predict(panel_model, validation_set, type = "response")
validation_roc <- roc(validation_set$Cancer, validation_probs)

cat("Biomarker Panel Performance:\n")
cat("Discovery AUC:", round(auc(discovery_roc), 3), "\n")
cat("Validation AUC:", round(auc(validation_roc), 3), "\n")

# Plot ROC curves
library(patchwork)
p1 <- ggroc(discovery_roc, color = "blue") +
  geom_abline(intercept = 1, slope = 1, linetype = "dashed") +
  labs(title = paste("Discovery Set (AUC =", round(auc(discovery_roc), 3), ")")) +
  theme_minimal()

p2 <- ggroc(validation_roc, color = "red") +
  geom_abline(intercept = 1, slope = 1, linetype = "dashed") +
  labs(title = paste("Validation Set (AUC =", round(auc(validation_roc), 3), ")")) +
  theme_minimal()

print(p1 | p2)

# Biomarker panel score distribution
validation_set$Panel_Score <- validation_probs

ggplot(validation_set, aes(x = Cancer, y = Panel_Score, fill = Cancer)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.5) +
  scale_fill_manual(values = c("lightblue", "lightcoral")) +
  labs(title = "Biomarker Panel Score Distribution",
       x = "Cancer Status", y = "Panel Score (Probability)") +
  theme_minimal()

# Optimal cutoff selection
optimal_cutoff <- coords(validation_roc, "best", ret = "threshold")
sensitivity_at_cutoff <- coords(validation_roc, optimal_cutoff, ret = "sensitivity")
specificity_at_cutoff <- coords(validation_roc, optimal_cutoff, ret = "specificity")

cat("Optimal cutoff:", round(optimal_cutoff, 3), "\n")
cat("Sensitivity:", round(sensitivity_at_cutoff, 3), "\n")
cat("Specificity:", round(specificity_at_cutoff, 3), "\n")
```

::: {.callout-note}
## Key Principles for Biological Classification Models

1. **Feature selection** is crucial - not all measured variables are informative
2. **Cross-validation** prevents overfitting, especially with high-dimensional data
3. **Independent validation** is essential for clinical biomarker development
4. **Biological interpretation** should guide model selection and feature engineering
5. **Multiple testing correction** is critical when screening many potential biomarkers
6. **Clinical context** determines optimal sensitivity/specificity trade-offs
:::

### Model Selection and Validation Strategies

#### Cross-Validation for Robust Performance Estimation

```{r}
#| echo: true
#| eval: true
library(caret)

# 10-fold cross-validation for biomarker panel
set.seed(1111)

# Define training control
train_control <- trainControl(
  method = "cv",
  number = 10,
  summaryFunction = twoClassSummary,
  classProbs = TRUE,
  savePredictions = TRUE
)

# Train model with cross-validation
cv_model <- train(
  panel_formula,
  data = discovery_set,
  method = "glm",
  family = "binomial",
  trControl = train_control,
  metric = "ROC"
)

print(cv_model)

# Cross-validation performance
cv_auc <- cv_model$results$ROC
cv_sensitivity <- cv_model$results$Sens
cv_specificity <- cv_model$results$Spec

cat("Cross-Validation Results:\n")
cat("Mean AUC:", round(cv_auc, 3), "\n")
cat("Mean Sensitivity:", round(cv_sensitivity, 3), "\n")
cat("Mean Specificity:", round(cv_specificity, 3), "\n")

# Plot cross-validation predictions
cv_predictions <- cv_model$pred
ggplot(cv_predictions, aes(x = obs, y = Cancer, fill = obs)) +
  geom_boxplot(alpha = 0.7) +
  labs(title = "Cross-Validation Predictions",
       x = "Observed Class", y = "Predicted Probability") +
  theme_minimal()
```

## Model Evaluation for Classification

### The Confusion Matrix

A confusion matrix is a table that shows how well our classification model performs. It's like a report card for prediction models.

::: {.callout-note}
## Think of it this way
Imagine you're a doctor using a test to diagnose disease. The confusion matrix shows:
- How many sick patients you correctly identified (True Positives)
- How many healthy patients you correctly identified (True Negatives)
- How many times you missed the disease (False Negatives)
- How many times you incorrectly diagnosed disease (False Positives)
:::

### 2×2 Confusion Matrix

|                | **Predicted** |           |
|----------------|:-------------:|:---------:|
| **Actual**     | **Positive**  | **Negative** |
| **Positive**   | TP            | FN        |
| **Negative**   | FP            | TN        |

Where:
- **TP (True Positives)**: Correctly predicted positive cases
- **TN (True Negatives)**: Correctly predicted negative cases
- **FP (False Positives)**: Incorrectly predicted positive (Type I error)
- **FN (False Negatives)**: Incorrectly predicted negative (Type II error)

### Example: COVID-19 Test Evaluation

Let's say we have a COVID-19 test and we tested 1000 people:

```{r}
#| echo: true
#| eval: true
# Create confusion matrix data
library(caret)

# Simulate COVID test results
set.seed(789)
n <- 1000
true_status <- c(rep("Positive", 100), rep("Negative", 900))  # 10% prevalence
test_sensitivity <- 0.95  # 95% of positive cases detected
test_specificity <- 0.98  # 98% of negative cases correctly identified

predicted_status <- ifelse(
  true_status == "Positive",
  ifelse(runif(sum(true_status == "Positive")) < test_sensitivity, "Positive", "Negative"),
  ifelse(runif(sum(true_status == "Negative")) < test_specificity, "Negative", "Positive")
)

# Create confusion matrix
cm <- confusionMatrix(as.factor(predicted_status), as.factor(true_status), positive = "Positive")
print(cm)

# Visualize confusion matrix
library(ggplot2)
cm_table <- as.data.frame(cm$table)
ggplot(cm_table, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), size = 12, color = "white") +
  scale_fill_gradient(low = "lightblue", high = "darkblue") +
  labs(title = "COVID-19 Test Confusion Matrix",
       x = "Actual Status", y = "Predicted Status") +
  theme_minimal() +
  theme(text = element_text(size = 12))
```

## Diagnostic Test Performance Metrics

From the confusion matrix, we can calculate several important metrics:

### Sensitivity (True Positive Rate)

**What it means**: Of all the people who actually have the disease, what percentage does our test catch?

$$\text{Sensitivity} = \frac{TP}{TP + FN}$$

**Example**: If sensitivity = 0.95, then our test catches 95% of COVID-positive patients.

### Specificity (True Negative Rate)

**What it means**: Of all the people who don't have the disease, what percentage does our test correctly identify as negative?

$$\text{Specificity} = \frac{TN}{TN + FP}$$

**Example**: If specificity = 0.98, then our test correctly identifies 98% of COVID-negative patients.

### Positive Predictive Value (PPV)

**What it means**: If the test is positive, what's the probability the person actually has the disease?

$$\text{PPV} = \frac{TP}{TP + FP}$$

### Negative Predictive Value (NPV)

**What it means**: If the test is negative, what's the probability the person actually doesn't have the disease?

$$\text{NPV} = \frac{TN}{TN + FN}$$

::: {.callout-warning}
## Important: PPV and NPV depend on disease prevalence!
In a population where disease is rare, even a good test will have many false positives, lowering PPV. In a high-prevalence population, the same test will have better PPV.
:::

```{r}
#| echo: true
#| eval: true
# Calculate metrics manually
calculate_metrics <- function(tp, tn, fp, fn) {
  sensitivity <- tp / (tp + fn)
  specificity <- tn / (tn + fp)
  ppv <- tp / (tp + fp)
  npv <- tn / (tn + fn)
  accuracy <- (tp + tn) / (tp + tn + fp + fn)

  return(list(
    Sensitivity = sensitivity,
    Specificity = specificity,
    PPV = ppv,
    NPV = npv,
    Accuracy = accuracy
  ))
}

# Example with our COVID data
metrics <- calculate_metrics(tp = 95, tn = 882, fp = 18, fn = 5)
print(metrics)
```

## ROC Curves and AUC

### What is an ROC Curve?

ROC stands for "Receiver Operating Characteristic." Think of it as a way to visualize the trade-off between catching true cases (sensitivity) and avoiding false alarms (1 - specificity).

**Real-world analogy**: Imagine you're a security guard with a metal detector. You can adjust the sensitivity:
- High sensitivity: Catches all weapons but sets off many false alarms
- Low sensitivity: Fewer false alarms but might miss some weapons

The ROC curve shows this trade-off at different threshold settings.

### Mathematical Definition

The ROC curve plots:
- **Y-axis**: True Positive Rate (Sensitivity) = $\frac{TP}{TP + FN}$
- **X-axis**: False Positive Rate (1 - Specificity) = $\frac{FP}{FP + TN}$

### Creating ROC Curves

```{r}
#| echo: true
#| eval: true
library(pROC)
library(ggplot2)

# Simulate biomarker data for disease diagnosis
set.seed(101)
n_healthy <- 500
n_diseased <- 200

# Healthy individuals: lower biomarker levels
healthy_biomarker <- rnorm(n_healthy, mean = 10, sd = 3)

# Diseased individuals: higher biomarker levels
diseased_biomarker <- rnorm(n_diseased, mean = 15, sd = 3)

# Combine data
biomarker_values <- c(healthy_biomarker, diseased_biomarker)
true_status <- c(rep(0, n_healthy), rep(1, n_diseased))

# Create ROC curve
roc_obj <- roc(true_status, biomarker_values)

# Plot ROC curve
ggroc(roc_obj, color = "blue", size = 1) +
  geom_abline(intercept = 1, slope = 1, linetype = "dashed", color = "red") +
  labs(title = "ROC Curve for Biomarker Test",
       x = "False Positive Rate (1 - Specificity)",
       y = "True Positive Rate (Sensitivity)") +
  theme_minimal() +
  annotate("text", x = 0.7, y = 0.3,
           label = paste("AUC =", round(auc(roc_obj), 3)), size = 5)
```

### Understanding AUC (Area Under the Curve)

The AUC summarizes the ROC curve into a single number between 0 and 1:

$$\text{AUC} = \int_0^1 \text{TPR}(t) \, d(\text{FPR}(t))$$

**Interpretation**:
- **AUC = 0.5**: Random guessing (coin flip)
- **AUC = 0.7**: Acceptable discrimination
- **AUC = 0.8**: Excellent discrimination
- **AUC = 0.9**: Outstanding discrimination
- **AUC = 1.0**: Perfect discrimination

::: {.callout-tip}
## Intuitive AUC Interpretation
AUC represents the probability that a randomly selected positive case will have a higher predicted probability than a randomly selected negative case.

If AUC = 0.8, then 80% of the time, a diseased person will have a higher biomarker value than a healthy person.
:::

### Comparing Multiple Tests

```{r}
#| echo: true
#| eval: true
# Simulate three different biomarkers
biomarker1 <- c(rnorm(n_healthy, 10, 3), rnorm(n_diseased, 15, 3))  # Good test
biomarker2 <- c(rnorm(n_healthy, 12, 4), rnorm(n_diseased, 14, 4))  # Moderate test
biomarker3 <- c(rnorm(n_healthy, 11, 5), rnorm(n_diseased, 13, 5))  # Poor test

# Create ROC curves
roc1 <- roc(true_status, biomarker1)
roc2 <- roc(true_status, biomarker2)
roc3 <- roc(true_status, biomarker3)

# Plot comparison
library(patchwork)
p1 <- ggroc(list("Biomarker 1" = roc1, "Biomarker 2" = roc2, "Biomarker 3" = roc3)) +
  scale_color_manual(values = c("blue", "green", "red")) +
  geom_abline(intercept = 1, slope = 1, linetype = "dashed", color = "black") +
  labs(title = "Comparison of Three Biomarkers",
       x = "False Positive Rate", y = "True Positive Rate") +
  theme_minimal()

# Print AUC values
cat("AUC Values:\n")
cat("Biomarker 1:", round(auc(roc1), 3), "\n")
cat("Biomarker 2:", round(auc(roc2), 3), "\n")
cat("Biomarker 3:", round(auc(roc3), 3), "\n")

print(p1)
```

### Optimal Threshold Selection

```{r}
#| echo: true
#| eval: true
# Find optimal threshold using Youden's J statistic
coords_all <- coords(roc1, "all", ret = c("threshold", "sensitivity", "specificity"))
coords_all$youden <- coords_all$sensitivity + coords_all$specificity - 1
optimal_threshold <- coords_all[which.max(coords_all$youden), ]

cat("Optimal Threshold Analysis:\n")
cat("Threshold:", round(optimal_threshold$threshold, 2), "\n")
cat("Sensitivity:", round(optimal_threshold$sensitivity, 3), "\n")
cat("Specificity:", round(optimal_threshold$specificity, 3), "\n")
cat("Youden's J:", round(optimal_threshold$youden, 3), "\n")

# Plot threshold selection
threshold_plot <- ggplot(coords_all, aes(x = threshold)) +
  geom_line(aes(y = sensitivity, color = "Sensitivity"), size = 1) +
  geom_line(aes(y = specificity, color = "Specificity"), size = 1) +
  geom_vline(xintercept = optimal_threshold$threshold, linetype = "dashed") +
  scale_color_manual(values = c("blue", "red")) +
  labs(title = "Sensitivity and Specificity vs Threshold",
       x = "Biomarker Threshold", y = "Rate", color = "Metric") +
  theme_minimal()

print(threshold_plot)
```

## Practical Applications in Biostatistics

### 1. Biomarker Validation

When developing diagnostic biomarkers:
- Use ROC analysis to assess discriminative ability
- Calculate AUC to compare different biomarkers
- Determine optimal cutoff points balancing sensitivity and specificity

### 2. Risk Prediction Models

In clinical risk assessment:
- Logistic regression to model disease probability
- Confusion matrices to evaluate model performance
- ROC curves to assess calibration across risk thresholds

### 3. Treatment Response Prediction

For personalized medicine:
- Classification models to predict treatment response
- Performance metrics to validate model utility
- Threshold optimization for clinical decision-making

::: {.callout-note}
## Key Takeaways

1. **Confusion matrices** provide a complete picture of classification performance
2. **Sensitivity and specificity** are fundamental test characteristics
3. **PPV and NPV** depend on disease prevalence in your population
4. **ROC curves** visualize the sensitivity-specificity trade-off
5. **AUC** provides a single metric for overall discriminative ability
6. **Threshold selection** should consider clinical consequences of false positives vs false negatives
:::

## Python Implementation

For those preferring Python, here's equivalent code:

```{python}
#| echo: true
#| eval: true
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, classification_report
from sklearn.linear_model import LogisticRegression

# Simulate data
np.random.seed(123)
n = 1000
age = np.random.normal(55, 12, n)
cholesterol = np.random.normal(200, 40, n)
smoking = np.random.binomial(1, 0.3, n)

# Create outcome
log_odds = -5 + 0.05*age + 0.01*cholesterol + 1.2*smoking
prob_disease = np.exp(log_odds)/(1 + np.exp(log_odds))
heart_disease = np.random.binomial(1, prob_disease, n)

# Fit logistic regression
X = np.column_stack([age, cholesterol, smoking])
model = LogisticRegression()
model.fit(X, heart_disease)

# Predictions
y_pred_proba = model.predict_proba(X)[:, 1]
y_pred = model.predict(X)

# Confusion matrix
cm = confusion_matrix(heart_disease, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

# ROC curve
fpr, tpr, thresholds = roc_curve(heart_disease, y_pred_proba)
auc_score = roc_auc_score(heart_disease, y_pred_proba)

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc_score:.3f})')
plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

# Classification report
print(classification_report(heart_disease, y_pred))
```