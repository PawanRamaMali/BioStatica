{
  "hash": "6d95cd3b44ac552bc4123fd234937332",
  "result": {
    "engine": "knitr",
    "markdown": "# Interrelationships & Modeling\n\nMove beyond simple group comparisons to understand relationships between variables and build predictive models.\n\n## Introduction\n\nIn biostatistics, we often need to understand relationships between variables and make predictions. This chapter covers fundamental techniques for exploring associations, building predictive models, and evaluating their performance in medical and biological contexts.\n\n## Correlation Analysis\n\n### Understanding Correlation\n\nCorrelation measures the strength and direction of a linear relationship between two continuous variables. In biostatistics and molecular biology, correlation analysis is fundamental for understanding biological relationships:\n\n**Common biological correlations:**\n- Gene expression levels between co-regulated genes\n- Protein abundance and mRNA expression\n- Tumor size and metastatic potential\n- Drug concentration and treatment response\n- Metabolite levels in biochemical pathways\n\n### Types of Correlation\n\n#### Pearson Correlation Coefficient\n\nThe **Pearson correlation coefficient** ($r$) measures linear relationships and ranges from -1 to +1:\n\n$$r = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n}(x_i - \\bar{x})^2 \\sum_{i=1}^{n}(y_i - \\bar{y})^2}}$$\n\n**Interpretation:**\n- $r = 1$: Perfect positive linear relationship\n- $r = 0$: No linear relationship\n- $r = -1$: Perfect negative linear relationship\n\n::: {.callout-tip}\n## Interpreting Correlation Strength in Biology\n- **|r| < 0.3**: Weak correlation (may still be biologically meaningful)\n- **0.3 ≤ |r| < 0.7**: Moderate correlation (often significant in biological systems)\n- **|r| ≥ 0.7**: Strong correlation (rare in biology due to noise and complexity)\n:::\n\n#### Spearman Rank Correlation\n\nThe **Spearman correlation coefficient** ($\\rho$) measures monotonic relationships (not necessarily linear):\n\n$$\\rho = 1 - \\frac{6\\sum d_i^2}{n(n^2-1)}$$\n\nWhere $d_i$ is the difference between ranks of corresponding values.\n\n**When to use Spearman:**\n- Non-linear but monotonic relationships\n- Ordinal data\n- Presence of outliers\n- Non-normally distributed data\n\n### Gene Expression Correlation Analysis\n\n#### Example 1: Co-expression of Related Genes\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(corrplot)\nlibrary(dplyr)\n\n# Simulate gene expression data for 5 genes across 100 samples\nset.seed(456)\nn_samples <- 100\n\n# Gene 1: Master regulator\ngene1 <- rnorm(n_samples, mean = 8, sd = 1.5)\n\n# Gene 2: Strongly co-expressed with Gene 1 (same pathway)\ngene2 <- 0.8 * gene1 + rnorm(n_samples, mean = 1, sd = 0.8)\n\n# Gene 3: Moderately co-expressed with Gene 1\ngene3 <- 0.5 * gene1 + rnorm(n_samples, mean = 2, sd = 1.2)\n\n# Gene 4: Negatively correlated with Gene 1 (antagonistic pathway)\ngene4 <- -0.6 * gene1 + rnorm(n_samples, mean = 10, sd = 1)\n\n# Gene 5: Independent gene (different pathway)\ngene5 <- rnorm(n_samples, mean = 6, sd = 1.8)\n\n# Create expression matrix\nexpression_data <- data.frame(\n  Sample_ID = paste0(\"Sample_\", 1:n_samples),\n  BRCA1 = gene1,      # DNA repair gene\n  BRCA2 = gene2,      # Co-expressed DNA repair gene\n  ATM = gene3,        # DNA damage checkpoint gene\n  MYC = gene4,        # Oncogene (often dysregulated when DNA repair is high)\n  GAPDH = gene5       # Housekeeping gene\n)\n\n# Calculate correlation matrix\ncor_matrix <- cor(expression_data[, -1])  # Exclude Sample_ID\ncor_pvalues <- cor.test(expression_data$BRCA1, expression_data$BRCA2)\n\nprint(\"Gene Expression Correlation Matrix:\")\nprint(round(cor_matrix, 3))\n\n# Visualize correlation matrix\ncorrplot(cor_matrix, method = \"color\", type = \"upper\",\n         addCoef.col = \"black\", tl.col = \"black\", tl.srt = 45,\n         title = \"Gene Co-expression Network\", mar = c(0,0,1,0))\n\n# Detailed analysis of BRCA1-BRCA2 correlation\nbrca_cor <- cor.test(expression_data$BRCA1, expression_data$BRCA2,\n                     method = \"pearson\")\n\ncat(\"BRCA1-BRCA2 Correlation Analysis:\\n\")\ncat(\"Pearson r =\", round(brca_cor$estimate, 3), \"\\n\")\ncat(\"P-value =\", format(brca_cor$p.value, scientific = TRUE), \"\\n\")\ncat(\"95% CI: [\", round(brca_cor$conf.int[1], 3), \", \",\n    round(brca_cor$conf.int[2], 3), \"]\\n\")\n\n# Scatter plot with biological interpretation\nggplot(expression_data, aes(x = BRCA1, y = BRCA2)) +\n  geom_point(alpha = 0.6, color = \"darkblue\") +\n  geom_smooth(method = \"lm\", color = \"red\", se = TRUE) +\n  labs(\n    title = \"Co-expression of DNA Repair Genes BRCA1 and BRCA2\",\n    subtitle = paste(\"r =\", round(brca_cor$estimate, 3),\n                     \", p =\", format(brca_cor$p.value, digits = 3)),\n    x = \"BRCA1 Expression (log2 FPKM)\",\n    y = \"BRCA2 Expression (log2 FPKM)\"\n  ) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 12, face = \"bold\"))\n```\n:::\n\n\n\n\n\n\n#### Example 2: Protein-mRNA Correlation Analysis\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate protein abundance vs mRNA expression data\nset.seed(789)\nn_genes <- 50\n\n# mRNA expression levels (log2 scale)\nmRNA_expression <- rnorm(n_genes, mean = 5, sd = 2)\n\n# Protein abundance (correlated with mRNA but with noise)\n# Translation efficiency varies between proteins\ntranslation_efficiency <- runif(n_genes, min = 0.3, max = 0.8)\nprotein_abundance <- translation_efficiency * mRNA_expression +\n                    rnorm(n_genes, mean = 0, sd = 0.8)\n\n# Create dataset\nproteomics_data <- data.frame(\n  Gene = paste0(\"Gene_\", 1:n_genes),\n  mRNA = mRNA_expression,\n  Protein = protein_abundance,\n  Translation_Efficiency = translation_efficiency\n)\n\n# Calculate correlations\npearson_cor <- cor.test(proteomics_data$mRNA, proteomics_data$Protein)\nspearman_cor <- cor.test(proteomics_data$mRNA, proteomics_data$Protein,\n                        method = \"spearman\")\n\ncat(\"mRNA-Protein Correlation Analysis:\\n\")\ncat(\"Pearson r =\", round(pearson_cor$estimate, 3),\n    \"(p =\", format(pearson_cor$p.value, digits = 3), \")\\n\")\ncat(\"Spearman ρ =\", round(spearman_cor$estimate, 3),\n    \"(p =\", format(spearman_cor$p.value, digits = 3), \")\\n\")\n\n# Visualization\np1 <- ggplot(proteomics_data, aes(x = mRNA, y = Protein)) +\n  geom_point(aes(color = Translation_Efficiency), size = 3, alpha = 0.7) +\n  geom_smooth(method = \"lm\", color = \"black\", linetype = \"dashed\") +\n  scale_color_gradient(low = \"lightblue\", high = \"darkred\",\n                      name = \"Translation\\nEfficiency\") +\n  labs(\n    title = \"mRNA Expression vs Protein Abundance\",\n    subtitle = \"Color indicates translation efficiency\",\n    x = \"mRNA Expression (log2 FPKM)\",\n    y = \"Protein Abundance (log2 intensity)\"\n  ) +\n  theme_minimal()\n\nprint(p1)\n\n# Identify outliers (genes with unusual mRNA-protein relationships)\nproteomics_data$residuals <- residuals(lm(Protein ~ mRNA, data = proteomics_data))\nproteomics_data$outlier <- abs(proteomics_data$residuals) > 2 * sd(proteomics_data$residuals)\n\ncat(\"Potential post-transcriptional regulation candidates:\\n\")\noutlier_genes <- proteomics_data[proteomics_data$outlier, ]\nprint(outlier_genes[, c(\"Gene\", \"mRNA\", \"Protein\", \"Translation_Efficiency\")])\n```\n:::\n\n\n\n\n\n\n### Tumor Biology Correlation Examples\n\n#### Example 3: Tumor Size and Metastatic Markers\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate tumor progression data\nset.seed(101)\nn_tumors <- 150\n\n# Primary tumor characteristics\ntumor_size <- rexp(n_tumors, rate = 0.5)  # Exponential distribution (realistic for tumor sizes)\ntumor_grade <- sample(1:3, n_tumors, replace = TRUE, prob = c(0.4, 0.4, 0.2))\n\n# Metastatic markers (higher in larger, higher-grade tumors)\n# VEGF: Vascular endothelial growth factor\nvegf_expression <- 2 + 0.3 * tumor_size + 0.5 * tumor_grade + rnorm(n_tumors, sd = 0.8)\n\n# MMP9: Matrix metalloproteinase (invasion marker)\nmmp9_expression <- 1.5 + 0.25 * tumor_size + 0.6 * tumor_grade + rnorm(n_tumors, sd = 0.6)\n\n# Ki67: Proliferation marker\nki67_percentage <- 10 + 8 * tumor_size + 5 * tumor_grade + rnorm(n_tumors, sd = 8)\nki67_percentage <- pmax(0, pmin(100, ki67_percentage))  # Bound between 0-100%\n\n# Create tumor dataset\ntumor_data <- data.frame(\n  Tumor_ID = paste0(\"T\", sprintf(\"%03d\", 1:n_tumors)),\n  Size_cm = tumor_size,\n  Grade = factor(tumor_grade, labels = c(\"Low\", \"Intermediate\", \"High\")),\n  VEGF = vegf_expression,\n  MMP9 = mmp9_expression,\n  Ki67_percent = ki67_percentage\n)\n\n# Correlation analysis\ncor_vegf_size <- cor.test(tumor_data$Size_cm, tumor_data$VEGF)\ncor_mmp9_size <- cor.test(tumor_data$Size_cm, tumor_data$MMP9)\ncor_ki67_size <- cor.test(tumor_data$Size_cm, tumor_data$Ki67_percent)\n\ncat(\"Tumor Size Correlation Analysis:\\n\")\ncat(\"Size vs VEGF: r =\", round(cor_vegf_size$estimate, 3),\n    \"(p =\", format(cor_vegf_size$p.value, digits = 3), \")\\n\")\ncat(\"Size vs MMP9: r =\", round(cor_mmp9_size$estimate, 3),\n    \"(p =\", format(cor_mmp9_size$p.value, digits = 3), \")\\n\")\ncat(\"Size vs Ki67: r =\", round(cor_ki67_size$estimate, 3),\n    \"(p =\", format(cor_ki67_size$p.value, digits = 3), \")\\n\")\n\n# Multi-panel visualization\nlibrary(patchwork)\n\np1 <- ggplot(tumor_data, aes(x = Size_cm, y = VEGF, color = Grade)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"black\") +\n  scale_color_manual(values = c(\"green\", \"orange\", \"red\")) +\n  labs(title = \"VEGF Expression vs Tumor Size\",\n       x = \"Tumor Size (cm)\", y = \"VEGF Expression\") +\n  theme_minimal()\n\np2 <- ggplot(tumor_data, aes(x = Size_cm, y = MMP9, color = Grade)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"black\") +\n  scale_color_manual(values = c(\"green\", \"orange\", \"red\")) +\n  labs(title = \"MMP9 Expression vs Tumor Size\",\n       x = \"Tumor Size (cm)\", y = \"MMP9 Expression\") +\n  theme_minimal()\n\np3 <- ggplot(tumor_data, aes(x = Size_cm, y = Ki67_percent, color = Grade)) +\n  geom_point(alpha = 0.7) +\n  geom_smooth(method = \"lm\", se = TRUE, color = \"black\") +\n  scale_color_manual(values = c(\"green\", \"orange\", \"red\")) +\n  labs(title = \"Ki67 Proliferation vs Tumor Size\",\n       x = \"Tumor Size (cm)\", y = \"Ki67 (%)\") +\n  theme_minimal()\n\n# Combine plots\ncombined_plot <- (p1 | p2) / p3\nprint(combined_plot)\n\n# Correlation matrix of all markers\nmarker_matrix <- tumor_data[, c(\"Size_cm\", \"VEGF\", \"MMP9\", \"Ki67_percent\")]\ncolnames(marker_matrix) <- c(\"Size\", \"VEGF\", \"MMP9\", \"Ki67\")\nmarker_cor <- cor(marker_matrix)\n\ncorrplot(marker_cor, method = \"color\", type = \"upper\",\n         addCoef.col = \"black\", tl.col = \"black\",\n         title = \"Tumor Marker Correlation Matrix\", mar = c(0,0,1,0))\n```\n:::\n\n\n\n\n\n\n### Advanced Correlation Techniques\n\n#### Partial Correlation\n\n**Partial correlation** measures the relationship between two variables while controlling for one or more confounding variables.\n\n**Formula for partial correlation:**\n$$r_{xy \\cdot z} = \\frac{r_{xy} - r_{xz}r_{yz}}{\\sqrt{(1-r_{xz}^2)(1-r_{yz}^2)}}$$\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ppcor)\n\n# Example: Gene expression controlling for cell cycle effects\n# Many genes appear correlated simply because they're all affected by cell cycle\n\nset.seed(112)\nn_samples <- 80\n\n# Cell cycle score (confounding variable)\ncell_cycle_score <- rnorm(n_samples, mean = 50, sd = 15)\n\n# Gene A: Affected by cell cycle + specific function\ngeneA <- 0.4 * cell_cycle_score + rnorm(n_samples, mean = 5, sd = 1.5)\n\n# Gene B: Affected by cell cycle + specific function + some correlation with A\ngeneB <- 0.3 * cell_cycle_score + 0.2 * geneA + rnorm(n_samples, mean = 6, sd = 1.2)\n\n# Gene C: Only affected by cell cycle (control)\ngeneC <- 0.5 * cell_cycle_score + rnorm(n_samples, mean = 4, sd = 1)\n\npartial_cor_data <- data.frame(\n  Sample = 1:n_samples,\n  Cell_Cycle = cell_cycle_score,\n  GeneA = geneA,\n  GeneB = geneB,\n  GeneC = geneC\n)\n\n# Calculate regular correlations\nregular_cor_AB <- cor.test(partial_cor_data$GeneA, partial_cor_data$GeneB)\nregular_cor_AC <- cor.test(partial_cor_data$GeneA, partial_cor_data$GeneC)\n\n# Calculate partial correlations (controlling for cell cycle)\npartial_cor_AB <- pcor.test(partial_cor_data$GeneA, partial_cor_data$GeneB,\n                           partial_cor_data$Cell_Cycle)\npartial_cor_AC <- pcor.test(partial_cor_data$GeneA, partial_cor_data$GeneC,\n                           partial_cor_data$Cell_Cycle)\n\ncat(\"Regular vs Partial Correlation Analysis:\\n\")\ncat(\"================================\\n\")\ncat(\"Gene A vs Gene B:\\n\")\ncat(\"  Regular correlation: r =\", round(regular_cor_AB$estimate, 3),\n    \"(p =\", format(regular_cor_AB$p.value, digits = 3), \")\\n\")\ncat(\"  Partial correlation: r =\", round(partial_cor_AB$estimate, 3),\n    \"(p =\", format(partial_cor_AB$p.value, digits = 3), \")\\n\\n\")\n\ncat(\"Gene A vs Gene C:\\n\")\ncat(\"  Regular correlation: r =\", round(regular_cor_AC$estimate, 3),\n    \"(p =\", format(regular_cor_AC$p.value, digits = 3), \")\\n\")\ncat(\"  Partial correlation: r =\", round(partial_cor_AC$estimate, 3),\n    \"(p =\", format(partial_cor_AC$p.value, digits = 3), \")\\n\")\n\n# Visualization\nlibrary(GGally)\nggpairs(partial_cor_data[, c(\"GeneA\", \"GeneB\", \"GeneC\", \"Cell_Cycle\")],\n        title = \"Pairwise Correlations: Genes and Cell Cycle\",\n        upper = list(continuous = wrap(\"cor\", size = 3)),\n        lower = list(continuous = wrap(\"points\", alpha = 0.5)))\n```\n:::\n\n\n\n\n\n\n#### Network Correlation Analysis\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(igraph)\nlibrary(ggraph)\n\n# Simulate pathway gene expression network\nset.seed(234)\nn_genes <- 20\n\n# Create a pathway with hub genes and their targets\npathway_genes <- paste0(\"Gene_\", LETTERS[1:n_genes])\n\n# Simulate expression data with network structure\nexpression_matrix <- matrix(rnorm(n_genes * 100), nrow = n_genes, ncol = 100)\nrownames(expression_matrix) <- pathway_genes\n\n# Add correlations based on known pathway interactions\n# Gene A is a master regulator\nexpression_matrix[1, ] <- rnorm(100, mean = 8, sd = 1.5)  # Gene A\n\n# Genes B, C, D are direct targets of A\nfor(i in 2:4) {\n  expression_matrix[i, ] <- 0.7 * expression_matrix[1, ] + rnorm(100, sd = 1)\n}\n\n# Genes E, F are targets of B\nfor(i in 5:6) {\n  expression_matrix[i, ] <- 0.6 * expression_matrix[2, ] + rnorm(100, sd = 1.2)\n}\n\n# Calculate correlation matrix\ngene_cor_matrix <- cor(t(expression_matrix))\n\n# Create network from correlations (threshold at |r| > 0.5)\ncor_threshold <- 0.5\nadjacency_matrix <- abs(gene_cor_matrix) > cor_threshold\ndiag(adjacency_matrix) <- FALSE  # Remove self-connections\n\n# Create igraph object\ngene_network <- graph_from_adjacency_matrix(adjacency_matrix, mode = \"undirected\")\nV(gene_network)$name <- pathway_genes\n\n# Add correlation weights as edge attributes\nedges <- get.edgelist(gene_network)\nedge_cors <- sapply(1:nrow(edges), function(i) {\n  gene1 <- edges[i, 1]\n  gene2 <- edges[i, 2]\n  gene_cor_matrix[gene1, gene2]\n})\nE(gene_network)$weight <- abs(edge_cors)\nE(gene_network)$correlation <- edge_cors\n\n# Calculate network properties\ndegree_centrality <- degree(gene_network)\nbetweenness_centrality <- betweenness(gene_network)\ncloseness_centrality <- closeness(gene_network)\n\nnetwork_properties <- data.frame(\n  Gene = names(degree_centrality),\n  Degree = degree_centrality,\n  Betweenness = betweenness_centrality,\n  Closeness = closeness_centrality\n)\n\ncat(\"Top hub genes (highest degree centrality):\\n\")\nprint(head(network_properties[order(-network_properties$Degree), ], 5))\n\n# Visualize network\nset.seed(345)\nggraph(gene_network, layout = 'stress') +\n  geom_edge_link(aes(width = weight, alpha = weight), color = \"gray50\") +\n  geom_node_point(aes(size = degree_centrality), color = \"steelblue\", alpha = 0.8) +\n  geom_node_text(aes(label = name), size = 3, repel = TRUE) +\n  scale_edge_width(range = c(0.5, 2), name = \"Correlation\") +\n  scale_edge_alpha(range = c(0.3, 0.8)) +\n  scale_size(range = c(3, 8), name = \"Degree\") +\n  labs(title = \"Gene Co-expression Network\",\n       subtitle = \"Node size = degree centrality, Edge width = correlation strength\") +\n  theme_graph()\n```\n:::\n\n\n\n\n\n\n::: {.callout-note}\n## Key Points for Biological Correlation Analysis\n\n1. **Effect sizes matter more than p-values** in large datasets\n2. **Partial correlation** helps identify direct vs indirect relationships\n3. **Multiple testing correction** is crucial for genome-wide analyses\n4. **Network analysis** reveals pathway-level organization\n5. **Biological interpretation** should guide statistical significance thresholds\n6. **Confounding variables** (batch effects, cell cycle, etc.) must be considered\n:::\n\n### Association Analysis Beyond Correlation\n\n#### Chi-square Test for Categorical Associations\n\nFor categorical variables (e.g., mutation status, tumor type, treatment response):\n\n$$\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}$$\n\nWhere $O_i$ is observed frequency and $E_i$ is expected frequency.\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example: Association between gene mutation and cancer subtype\nset.seed(456)\nn_patients <- 200\n\n# Simulate cancer subtypes\ncancer_subtype <- sample(c(\"Luminal A\", \"Luminal B\", \"HER2+\", \"Triple Negative\"),\n                        n_patients, prob = c(0.4, 0.2, 0.15, 0.25), replace = TRUE)\n\n# Simulate TP53 mutation status (higher in aggressive subtypes)\nmutation_probs <- ifelse(cancer_subtype %in% c(\"HER2+\", \"Triple Negative\"), 0.7, 0.2)\ntp53_mutation <- rbinom(n_patients, 1, mutation_probs)\n\n# Create contingency table\ncontingency_table <- table(cancer_subtype, tp53_mutation)\ncolnames(contingency_table) <- c(\"TP53 Wild-type\", \"TP53 Mutated\")\n\nprint(\"Contingency Table: Cancer Subtype vs TP53 Mutation\")\nprint(contingency_table)\n\n# Chi-square test\nchi_test <- chisq.test(contingency_table)\nprint(chi_test)\n\n# Effect size (Cramér's V)\ncramers_v <- sqrt(chi_test$statistic / (n_patients * (min(nrow(contingency_table),\n                  ncol(contingency_table)) - 1)))\ncat(\"Cramér's V =\", round(cramers_v, 3), \"\\n\")\n\n# Visualization\nlibrary(ggplot2)\nassociation_data <- data.frame(\n  Subtype = cancer_subtype,\n  TP53_Status = factor(tp53_mutation, labels = c(\"Wild-type\", \"Mutated\"))\n)\n\nggplot(association_data, aes(x = Subtype, fill = TP53_Status)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(\"lightblue\", \"darkred\")) +\n  labs(title = \"TP53 Mutation Frequency by Cancer Subtype\",\n       y = \"Proportion\", x = \"Cancer Subtype\", fill = \"TP53 Status\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n:::\n\n\n\n\n\n\n## Chi-squared Goodness of Fit Test in Biology\n\n### Understanding Goodness of Fit\n\nThe **chi-squared goodness of fit test** determines whether observed data follows a specific expected distribution or theoretical model. In biology, this test is essential for:\n\n- Testing Hardy-Weinberg equilibrium in population genetics\n- Validating Mendelian inheritance patterns\n- Assessing whether gene expression follows specific distributions\n- Testing model assumptions in biological data\n- Validating theoretical predictions against experimental observations\n\n### Mathematical Foundation\n\nThe chi-squared goodness of fit statistic is:\n\n$$\\chi^2 = \\sum_{i=1}^{k} \\frac{(O_i - E_i)^2}{E_i}$$\n\nWhere:\n- $O_i$ = Observed frequency in category $i$\n- $E_i$ = Expected frequency in category $i$ under the null hypothesis\n- $k$ = Number of categories\n- Degrees of freedom = $k - 1 - p$ (where $p$ is the number of estimated parameters)\n\n**Assumptions:**\n1. Data are frequencies or counts (not proportions)\n2. Categories are mutually exclusive and exhaustive\n3. Expected frequency in each category ≥ 5\n4. Observations are independent\n\n### Hardy-Weinberg Equilibrium Testing\n\n#### Example 1: Single Gene Analysis\n\nThe Hardy-Weinberg principle states that allele frequencies remain constant in a population under specific conditions. For a gene with two alleles (A and a) with frequencies $p$ and $q$:\n\n**Expected genotype frequencies:**\n- AA: $p^2$\n- Aa: $2pq$\n- aa: $q^2$\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example: Testing Hardy-Weinberg equilibrium for a disease susceptibility gene\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Simulate population genetics data\nset.seed(1234)\nn_individuals <- 1000\n\n# True allele frequencies\np_A <- 0.3  # Frequency of A allele (protective)\nq_a <- 0.7  # Frequency of a allele (risk)\n\n# Simulate genotypes under Hardy-Weinberg equilibrium\n# Then add slight deviation to make it realistic\nhw_probs <- c(p_A^2, 2*p_A*q_a, q_a^2)  # AA, Aa, aa\nnames(hw_probs) <- c(\"AA\", \"Aa\", \"aa\")\n\n# Observed genotypes (with slight deviation from HWE)\nobserved_counts <- c(\n  AA = 85,   # Expected: p² × 1000 = 90\n  Aa = 435,  # Expected: 2pq × 1000 = 420\n  aa = 480   # Expected: q² × 1000 = 490\n)\n\n# Calculate expected counts under Hardy-Weinberg\ntotal_individuals <- sum(observed_counts)\nexpected_counts <- hw_probs * total_individuals\n\n# Estimate allele frequencies from observed data\ntotal_alleles <- 2 * total_individuals\nfreq_A_observed <- (2 * observed_counts[\"AA\"] + observed_counts[\"Aa\"]) / total_alleles\nfreq_a_observed <- 1 - freq_A_observed\n\ncat(\"Population Genetics Analysis:\\n\")\ncat(\"============================\\n\")\ncat(\"Sample size:\", total_individuals, \"individuals\\n\")\ncat(\"Observed allele frequencies:\\n\")\ncat(\"  A allele:\", round(freq_A_observed, 3), \"\\n\")\ncat(\"  a allele:\", round(freq_a_observed, 3), \"\\n\\n\")\n\n# Expected counts under HWE using observed allele frequencies\nexpected_HWE <- c(\n  AA = freq_A_observed^2 * total_individuals,\n  Aa = 2 * freq_A_observed * freq_a_observed * total_individuals,\n  aa = freq_a_observed^2 * total_individuals\n)\n\n# Chi-squared goodness of fit test\nhwe_test <- chisq.test(observed_counts, p = expected_HWE/sum(expected_HWE))\n\ncat(\"Hardy-Weinberg Equilibrium Test:\\n\")\ncat(\"Observed vs Expected genotype counts:\\n\")\ncomparison_table <- data.frame(\n  Genotype = names(observed_counts),\n  Observed = observed_counts,\n  Expected_HWE = round(expected_HWE, 1),\n  Difference = observed_counts - expected_HWE\n)\nprint(comparison_table)\n\ncat(\"\\nChi-squared test results:\\n\")\ncat(\"Chi-squared =\", round(hwe_test$statistic, 3), \"\\n\")\ncat(\"df =\", hwe_test$parameter, \"\\n\")\ncat(\"p-value =\", format(hwe_test$p.value, scientific = TRUE), \"\\n\")\n\nif(hwe_test$p.value < 0.05) {\n  cat(\"Conclusion: Population deviates significantly from Hardy-Weinberg equilibrium\\n\")\n} else {\n  cat(\"Conclusion: Population is in Hardy-Weinberg equilibrium\\n\")\n}\n\n# Visualization\nhw_data <- data.frame(\n  Genotype = factor(rep(names(observed_counts), 2), levels = c(\"AA\", \"Aa\", \"aa\")),\n  Count = c(observed_counts, expected_HWE),\n  Type = rep(c(\"Observed\", \"Expected (HWE)\"), each = 3)\n)\n\nggplot(hw_data, aes(x = Genotype, y = Count, fill = Type)) +\n  geom_col(position = \"dodge\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"steelblue\", \"orange\")) +\n  labs(title = \"Hardy-Weinberg Equilibrium Test\",\n       subtitle = paste(\"χ² =\", round(hwe_test$statistic, 2),\n                        \", p =\", format(hwe_test$p.value, digits = 3)),\n       x = \"Genotype\", y = \"Count\") +\n  theme_minimal() +\n  geom_text(aes(label = round(Count, 0)), position = position_dodge(width = 0.9),\n            vjust = -0.3, size = 3)\n```\n:::\n\n\n\n\n\n\n#### Example 2: Multiple Alleles System\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example: ABO blood group system (multiple alleles)\n# Alleles: A, B, O with frequencies p, q, r\n# Genotypes: AA, AO (Type A), BB, BO (Type B), AB (Type AB), OO (Type O)\n\nset.seed(5678)\n\n# Population data for ABO blood groups\nobserved_phenotypes <- c(\n  TypeA = 420,   # AA + AO genotypes\n  TypeB = 280,   # BB + BO genotypes\n  TypeAB = 110,  # AB genotype\n  TypeO = 190    # OO genotype\n)\n\ntotal_n <- sum(observed_phenotypes)\n\n# Estimate allele frequencies using maximum likelihood\n# For ABO system: p + q + r = 1, where p=freq(A), q=freq(B), r=freq(O)\n# Type O frequency = r², so r = sqrt(freq_O)\nr_freq <- sqrt(observed_phenotypes[\"TypeO\"] / total_n)\n\n# Type A + Type O = (p + r)², so p + r = sqrt(freq_A + freq_O)\nfreq_A_O <- (observed_phenotypes[\"TypeA\"] + observed_phenotypes[\"TypeO\"]) / total_n\np_plus_r <- sqrt(freq_A_O)\np_freq <- p_plus_r - r_freq\n\n# Type B + Type O = (q + r)², so q + r = sqrt(freq_B + freq_O)\nfreq_B_O <- (observed_phenotypes[\"TypeB\"] + observed_phenotypes[\"TypeO\"]) / total_n\nq_plus_r <- sqrt(freq_B_O)\nq_freq <- q_plus_r - r_freq\n\ncat(\"ABO Blood Group Analysis:\\n\")\ncat(\"=========================\\n\")\ncat(\"Estimated allele frequencies:\\n\")\ncat(\"A allele (p):\", round(p_freq, 3), \"\\n\")\ncat(\"B allele (q):\", round(q_freq, 3), \"\\n\")\ncat(\"O allele (r):\", round(r_freq, 3), \"\\n\")\ncat(\"Sum:\", round(p_freq + q_freq + r_freq, 3), \"\\n\\n\")\n\n# Expected phenotype frequencies under HWE\nexpected_phenotypes <- c(\n  TypeA = (p_freq^2 + 2*p_freq*r_freq) * total_n,    # AA + AO\n  TypeB = (q_freq^2 + 2*q_freq*r_freq) * total_n,    # BB + BO\n  TypeAB = (2*p_freq*q_freq) * total_n,               # AB\n  TypeO = (r_freq^2) * total_n                        # OO\n)\n\n# Chi-squared goodness of fit test\nabo_test <- chisq.test(observed_phenotypes, p = expected_phenotypes/sum(expected_phenotypes))\n\ncat(\"Observed vs Expected phenotype counts:\\n\")\nabo_comparison <- data.frame(\n  Blood_Type = names(observed_phenotypes),\n  Observed = observed_phenotypes,\n  Expected = round(expected_phenotypes, 1),\n  Residual = round((observed_phenotypes - expected_phenotypes), 1)\n)\nprint(abo_comparison)\n\ncat(\"\\nChi-squared goodness of fit test:\\n\")\ncat(\"Chi-squared =\", round(abo_test$statistic, 3), \"\\n\")\ncat(\"df =\", abo_test$parameter, \"\\n\")\ncat(\"p-value =\", format(abo_test$p.value, digits = 4), \"\\n\")\n\n# Visualization\nabo_data <- data.frame(\n  Blood_Type = factor(rep(names(observed_phenotypes), 2)),\n  Count = c(observed_phenotypes, expected_phenotypes),\n  Type = rep(c(\"Observed\", \"Expected\"), each = 4)\n)\n\nggplot(abo_data, aes(x = Blood_Type, y = Count, fill = Type)) +\n  geom_col(position = \"dodge\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"darkred\", \"lightcoral\")) +\n  labs(title = \"ABO Blood Group Distribution\",\n       subtitle = \"Testing Hardy-Weinberg Equilibrium\",\n       x = \"Blood Type\", y = \"Count\") +\n  theme_minimal()\n```\n:::\n\n\n\n\n\n\n### Mendelian Inheritance Pattern Testing\n\n#### Example 3: Testing Classical Mendelian Ratios\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example: F2 generation cross testing 9:3:3:1 ratio\n# Dihybrid cross: AaBb × AaBb\n# Expected ratio: 9 A_B_ : 3 A_bb : 3 aaB_ : 1 aabb\n\nset.seed(9999)\n\n# Simulated F2 generation data\nobserved_F2 <- c(\n  Purple_Round = 315,    # A_B_ (dominant for both traits)\n  Purple_Wrinkled = 108, # A_bb (dominant for trait A, recessive for B)\n  Yellow_Round = 101,    # aaB_ (recessive for A, dominant for B)\n  Yellow_Wrinkled = 32   # aabb (recessive for both traits)\n)\n\ntotal_offspring <- sum(observed_F2)\n\n# Expected Mendelian ratio: 9:3:3:1\nmendelian_ratio <- c(9, 3, 3, 1)\nexpected_F2 <- (mendelian_ratio / sum(mendelian_ratio)) * total_offspring\n\ncat(\"Dihybrid Cross Analysis (F2 Generation):\\n\")\ncat(\"=======================================\\n\")\ncat(\"Total offspring:\", total_offspring, \"\\n\\n\")\n\n# Chi-squared test for Mendelian inheritance\nmendelian_test <- chisq.test(observed_F2, p = expected_F2/sum(expected_F2))\n\ncat(\"Testing 9:3:3:1 Mendelian ratio:\\n\")\nmendel_comparison <- data.frame(\n  Phenotype = names(observed_F2),\n  Observed = observed_F2,\n  Expected_931 = round(expected_F2, 1),\n  Ratio_Observed = round(observed_F2 / min(observed_F2), 2),\n  Ratio_Expected = mendelian_ratio\n)\nprint(mendel_comparison)\n\ncat(\"\\nChi-squared goodness of fit test:\\n\")\ncat(\"Chi-squared =\", round(mendelian_test$statistic, 3), \"\\n\")\ncat(\"df =\", mendelian_test$parameter, \"\\n\")\ncat(\"p-value =\", format(mendelian_test$p.value, digits = 4), \"\\n\")\n\nif(mendelian_test$p.value > 0.05) {\n  cat(\"Conclusion: Data consistent with 9:3:3:1 Mendelian ratio\\n\")\n} else {\n  cat(\"Conclusion: Data deviates significantly from expected Mendelian ratio\\n\")\n}\n\n# Calculate individual chi-squared contributions\nchi_contributions <- (observed_F2 - expected_F2)^2 / expected_F2\ncat(\"\\nContribution to chi-squared by phenotype:\\n\")\nfor(i in 1:length(chi_contributions)) {\n  cat(names(chi_contributions)[i], \":\", round(chi_contributions[i], 3), \"\\n\")\n}\n\n# Visualization\nmendel_data <- data.frame(\n  Phenotype = factor(rep(names(observed_F2), 2)),\n  Count = c(observed_F2, expected_F2),\n  Type = rep(c(\"Observed\", \"Expected (9:3:3:1)\"), each = 4)\n)\n\nggplot(mendel_data, aes(x = Phenotype, y = Count, fill = Type)) +\n  geom_col(position = \"dodge\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"darkgreen\", \"lightgreen\")) +\n  labs(title = \"Dihybrid Cross: Testing Mendelian Inheritance\",\n       subtitle = paste(\"χ² =\", round(mendelian_test$statistic, 2),\n                        \", p =\", format(mendelian_test$p.value, digits = 3)),\n       x = \"Phenotype\", y = \"Count\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n:::\n\n\n\n\n\n\n### Distribution Fitting in Biology\n\n#### Example 4: Testing Gene Expression Distribution\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example: Testing if gene expression follows a normal distribution\nlibrary(fitdistrplus)\n\nset.seed(2468)\n\n# Simulate gene expression data (log-transformed FPKM values)\n# True distribution is slightly skewed (log-normal)\nn_genes <- 500\ntrue_expression <- rlnorm(n_genes, meanlog = 2, sdlog = 0.8)\nlog_expression <- log2(true_expression)\n\n# Test normality using chi-squared goodness of fit\n# First, create bins for the continuous data\nn_bins <- 8\nexpression_breaks <- quantile(log_expression, probs = seq(0, 1, length.out = n_bins + 1))\nobserved_counts <- table(cut(log_expression, breaks = expression_breaks, include.lowest = TRUE))\n\n# Estimate normal distribution parameters\nmean_expr <- mean(log_expression)\nsd_expr <- sd(log_expression)\n\n# Calculate expected frequencies under normal distribution\nbin_probs <- numeric(n_bins)\nfor(i in 1:n_bins) {\n  lower <- expression_breaks[i]\n  upper <- expression_breaks[i + 1]\n  bin_probs[i] <- pnorm(upper, mean_expr, sd_expr) - pnorm(lower, mean_expr, sd_expr)\n}\n\nexpected_counts <- bin_probs * n_genes\n\ncat(\"Gene Expression Distribution Analysis:\\n\")\ncat(\"====================================\\n\")\ncat(\"Sample size:\", n_genes, \"genes\\n\")\ncat(\"Mean expression:\", round(mean_expr, 2), \"log2(FPKM)\\n\")\ncat(\"SD expression:\", round(sd_expr, 2), \"log2(FPKM)\\n\\n\")\n\n# Chi-squared goodness of fit test for normality\n# df = number of bins - 1 - number of estimated parameters (2 for normal: mean, sd)\nnormality_test <- chisq.test(as.numeric(observed_counts), p = bin_probs)\n\ncat(\"Testing normality of gene expression:\\n\")\nnorm_comparison <- data.frame(\n  Bin = 1:n_bins,\n  Range = paste0(\"(\", round(expression_breaks[1:n_bins], 1), \", \",\n                round(expression_breaks[2:(n_bins+1)], 1), \"]\"),\n  Observed = as.numeric(observed_counts),\n  Expected = round(expected_counts, 1)\n)\nprint(norm_comparison)\n\ncat(\"\\nChi-squared goodness of fit test:\\n\")\ncat(\"Chi-squared =\", round(normality_test$statistic, 3), \"\\n\")\ncat(\"df =\", normality_test$parameter, \"\\n\")\ncat(\"p-value =\", format(normality_test$p.value, digits = 4), \"\\n\")\n\n# Alternative: Shapiro-Wilk test for comparison (for smaller samples)\nif(n_genes <= 5000) {\n  shapiro_test <- shapiro.test(log_expression)\n  cat(\"\\nShapiro-Wilk test (for comparison):\\n\")\n  cat(\"W =\", round(shapiro_test$statistic, 4), \"\\n\")\n  cat(\"p-value =\", format(shapiro_test$p.value, digits = 4), \"\\n\")\n}\n\n# Visualization: Q-Q plot and histogram\nlibrary(patchwork)\n\n# Q-Q plot\nqq_data <- data.frame(\n  Theoretical = qnorm(ppoints(n_genes)),\n  Sample = sort(scale(log_expression)[, 1])\n)\n\np1 <- ggplot(qq_data, aes(x = Theoretical, y = Sample)) +\n  geom_point(alpha = 0.6) +\n  geom_abline(slope = 1, intercept = 0, color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Q-Q Plot: Testing Normality\",\n       x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n  theme_minimal()\n\n# Histogram with normal overlay\np2 <- ggplot(data.frame(expression = log_expression), aes(x = expression)) +\n  geom_histogram(aes(y = ..density..), bins = 20, alpha = 0.7, fill = \"skyblue\") +\n  stat_function(fun = dnorm, args = list(mean = mean_expr, sd = sd_expr),\n                color = \"red\", size = 1, linetype = \"dashed\") +\n  labs(title = \"Gene Expression Distribution\",\n       subtitle = \"Blue: Observed, Red: Normal distribution\",\n       x = \"log2(FPKM)\", y = \"Density\") +\n  theme_minimal()\n\nprint(p1 | p2)\n\n# Test for other distributions\ncat(\"\\nTesting alternative distributions:\\n\")\n\n# Log-normal test (on original scale)\noriginal_data <- 2^log_expression\nlnorm_fit <- fitdist(original_data, \"lnorm\")\nlnorm_gof <- gofstat(lnorm_fit)\ncat(\"Log-normal distribution:\\n\")\ncat(\"  Anderson-Darling A² =\", round(lnorm_gof$ad, 3), \"\\n\")\ncat(\"  Kolmogorov-Smirnov D =\", round(lnorm_gof$ks, 3), \"\\n\")\n\n# Gamma distribution test\ngamma_fit <- fitdist(original_data, \"gamma\")\ngamma_gof <- gofstat(gamma_fit)\ncat(\"Gamma distribution:\\n\")\ncat(\"  Anderson-Darling A² =\", round(gamma_gof$ad, 3), \"\\n\")\ncat(\"  Kolmogorov-Smirnov D =\", round(gamma_gof$ks, 3), \"\\n\")\n```\n:::\n\n\n\n\n\n\n#### Example 5: Mutation Rate Distribution\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example: Testing if mutations follow a Poisson distribution\nset.seed(3579)\n\n# Simulate mutation count data across genomic regions\nn_regions <- 200\nmean_mutations <- 2.5\n\n# Generate data with slight overdispersion (negative binomial)\n# But test against Poisson assumption\nobserved_mutations <- rnbinom(n_regions, size = 10, mu = mean_mutations)\n\n# Create frequency table\nmutation_counts <- table(observed_mutations)\nmax_mutations <- max(observed_mutations)\n\n# Expected frequencies under Poisson distribution\nlambda_est <- mean(observed_mutations)\nexpected_poisson <- dpois(0:max_mutations, lambda_est) * n_regions\n\n# Match observed and expected for chi-squared test\nobserved_freq <- numeric(max_mutations + 1)\nnames(observed_freq) <- 0:max_mutations\n\nfor(i in names(mutation_counts)) {\n  observed_freq[i] <- mutation_counts[i]\n}\n\n# Combine rare categories (expected < 5) for valid chi-squared test\ncombine_threshold <- 5\nlast_valid_category <- max_mutations\n\nfor(i in max_mutations:0) {\n  if(expected_poisson[i + 1] < combine_threshold) {\n    last_valid_category <- i - 1\n  } else {\n    break\n  }\n}\n\nif(last_valid_category < max_mutations) {\n  # Combine categories with expected < 5\n  observed_combined <- observed_freq[1:(last_valid_category + 1)]\n  observed_combined[length(observed_combined)] <- sum(observed_freq[(last_valid_category + 1):length(observed_freq)])\n\n  expected_combined <- expected_poisson[1:(last_valid_category + 1)]\n  expected_combined[length(expected_combined)] <- sum(expected_poisson[(last_valid_category + 1):length(expected_poisson)])\n\n  category_names <- c(0:last_valid_category, paste0(last_valid_category + 1, \"+\"))\n} else {\n  observed_combined <- observed_freq\n  expected_combined <- expected_poisson\n  category_names <- 0:max_mutations\n}\n\ncat(\"Mutation Distribution Analysis:\\n\")\ncat(\"==============================\\n\")\ncat(\"Sample size:\", n_regions, \"genomic regions\\n\")\ncat(\"Mean mutations per region:\", round(lambda_est, 2), \"\\n\")\ncat(\"Variance:\", round(var(observed_mutations), 2), \"\\n\")\ncat(\"Variance-to-mean ratio:\", round(var(observed_mutations)/mean(observed_mutations), 2), \"\\n\")\ncat(\"(Poisson: ratio = 1, Overdispersed: ratio > 1)\\n\\n\")\n\n# Chi-squared goodness of fit test\npoisson_test <- chisq.test(observed_combined, p = expected_combined/sum(expected_combined))\n\ncat(\"Testing Poisson distribution:\\n\")\npoisson_comparison <- data.frame(\n  Mutations = category_names,\n  Observed = observed_combined,\n  Expected_Poisson = round(expected_combined, 1),\n  Deviation = round(observed_combined - expected_combined, 1)\n)\nprint(poisson_comparison)\n\ncat(\"\\nChi-squared goodness of fit test:\\n\")\ncat(\"Chi-squared =\", round(poisson_test$statistic, 3), \"\\n\")\ncat(\"df =\", poisson_test$parameter, \"\\n\")\ncat(\"p-value =\", format(poisson_test$p.value, digits = 4), \"\\n\")\n\nif(poisson_test$p.value > 0.05) {\n  cat(\"Conclusion: Mutation counts consistent with Poisson distribution\\n\")\n} else {\n  cat(\"Conclusion: Mutation counts deviate from Poisson distribution\\n\")\n  cat(\"Consider: Negative binomial (overdispersion) or zero-inflated models\\n\")\n}\n\n# Visualization\nmutation_data <- data.frame(\n  Mutations = factor(rep(category_names, 2)),\n  Count = c(observed_combined, expected_combined),\n  Type = rep(c(\"Observed\", \"Expected (Poisson)\"), each = length(category_names))\n)\n\nggplot(mutation_data, aes(x = Mutations, y = Count, fill = Type)) +\n  geom_col(position = \"dodge\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"purple\", \"gold\")) +\n  labs(title = \"Mutation Count Distribution\",\n       subtitle = paste(\"Testing Poisson model (λ =\", round(lambda_est, 2), \")\"),\n       x = \"Number of Mutations\", y = \"Frequency\") +\n  theme_minimal()\n\n# Additional overdispersion test\ncat(\"\\nOverdispersion test:\\n\")\nif(var(observed_mutations) > mean(observed_mutations) * 1.2) {\n  cat(\"Evidence of overdispersion - consider negative binomial model\\n\")\n\n  # Fit negative binomial for comparison\n  library(MASS)\n  nb_params <- fitdistr(observed_mutations, \"negative binomial\")\n  cat(\"Negative binomial parameters:\\n\")\n  cat(\"  size =\", round(nb_params$estimate[\"size\"], 2), \"\\n\")\n  cat(\"  mu =\", round(nb_params$estimate[\"mu\"], 2), \"\\n\")\n} else {\n  cat(\"No strong evidence of overdispersion\\n\")\n}\n```\n:::\n\n\n\n\n\n\n### Model Adequacy Testing\n\n#### Example 6: Testing Regression Model Assumptions\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Example: Testing normality of residuals in biological regression\nset.seed(4680)\n\n# Simulate dose-response data with non-normal errors\nn_doses <- 60\ndrug_dose <- rep(c(0, 1, 2, 5, 10, 20), each = 10)\n\n# True response with slight heteroscedasticity\ntrue_response <- 10 + 3 * log(drug_dose + 1) + rnorm(n_doses, sd = 0.5 + 0.1 * drug_dose)\n\ndose_response_data <- data.frame(\n  Dose = drug_dose,\n  Response = true_response\n)\n\n# Fit linear regression model\nresponse_model <- lm(Response ~ log(Dose + 1), data = dose_response_data)\nsummary(response_model)\n\n# Extract residuals\nresiduals_data <- data.frame(\n  Fitted = fitted(response_model),\n  Residuals = residuals(response_model),\n  Standardized_Residuals = rstandard(response_model)\n)\n\n# Test normality of residuals using chi-squared\nn_bins_resid <- 6\nresidual_breaks <- quantile(residuals_data$Standardized_Residuals,\n                           probs = seq(0, 1, length.out = n_bins_resid + 1))\nobserved_resid_counts <- table(cut(residuals_data$Standardized_Residuals,\n                                  breaks = residual_breaks, include.lowest = TRUE))\n\n# Expected frequencies under standard normal\nresid_bin_probs <- numeric(n_bins_resid)\nfor(i in 1:n_bins_resid) {\n  lower <- residual_breaks[i]\n  upper <- residual_breaks[i + 1]\n  resid_bin_probs[i] <- pnorm(upper) - pnorm(lower)\n}\n\nexpected_resid_counts <- resid_bin_probs * n_doses\n\n# Chi-squared test for residual normality\nresidual_normality_test <- chisq.test(as.numeric(observed_resid_counts),\n                                     p = resid_bin_probs)\n\ncat(\"Regression Model Diagnostics:\\n\")\ncat(\"============================\\n\")\ncat(\"Testing normality of standardized residuals:\\n\")\n\nresid_comparison <- data.frame(\n  Bin = 1:n_bins_resid,\n  Observed = as.numeric(observed_resid_counts),\n  Expected = round(expected_resid_counts, 1)\n)\nprint(resid_comparison)\n\ncat(\"\\nChi-squared test for residual normality:\\n\")\ncat(\"Chi-squared =\", round(residual_normality_test$statistic, 3), \"\\n\")\ncat(\"df =\", residual_normality_test$parameter, \"\\n\")\ncat(\"p-value =\", format(residual_normality_test$p.value, digits = 4), \"\\n\")\n\n# Diagnostic plots\nlibrary(patchwork)\n\np1 <- ggplot(residuals_data, aes(x = Fitted, y = Residuals)) +\n  geom_point(alpha = 0.7) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  geom_smooth(se = FALSE, color = \"blue\") +\n  labs(title = \"Residuals vs Fitted Values\",\n       x = \"Fitted Values\", y = \"Residuals\") +\n  theme_minimal()\n\np2 <- ggplot(residuals_data, aes(sample = Standardized_Residuals)) +\n  geom_qq() +\n  geom_qq_line(color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Q-Q Plot of Standardized Residuals\",\n       x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n  theme_minimal()\n\nprint(p1 | p2)\n\n# Additional tests\ncat(\"\\nAdditional normality tests:\\n\")\nif(n_doses <= 5000) {\n  shapiro_resid <- shapiro.test(residuals_data$Standardized_Residuals)\n  cat(\"Shapiro-Wilk test: W =\", round(shapiro_resid$statistic, 4),\n      \", p =\", format(shapiro_resid$p.value, digits = 4), \"\\n\")\n}\n\n# Test for heteroscedasticity\nlibrary(car)\nbp_test <- ncvTest(response_model)\ncat(\"Breusch-Pagan test for heteroscedasticity:\\n\")\ncat(\"Chi-squared =\", round(bp_test$ChiSquare, 3),\n    \", p =\", format(bp_test$p, digits = 4), \"\\n\")\n\n# Recommendations based on test results\ncat(\"\\nModel adequacy assessment:\\n\")\nif(residual_normality_test$p.value < 0.05) {\n  cat(\"- Residuals deviate from normality - consider transformations\\n\")\n} else {\n  cat(\"- Residuals approximately normal\\n\")\n}\n\nif(bp_test$p < 0.05) {\n  cat(\"- Evidence of heteroscedasticity - consider weighted regression\\n\")\n} else {\n  cat(\"- Homoscedasticity assumption satisfied\\n\")\n}\n```\n:::\n\n\n\n\n\n\n::: {.callout-warning}\n## Important Considerations for Chi-squared Goodness of Fit Tests\n\n1. **Sample size requirements**: Expected frequency ≥ 5 in each category\n2. **Parameter estimation**: Degrees of freedom = categories - 1 - estimated parameters\n3. **Binning continuous data**: Choice of bins can affect results\n4. **Multiple testing**: Correct for multiple comparisons when testing many distributions\n5. **Biological interpretation**: Statistical significance doesn't always imply biological significance\n6. **Alternative tests**: Consider Kolmogorov-Smirnov, Anderson-Darling for continuous data\n:::\n\n::: {.callout-note}\n## Key Applications in Biology\n\n1. **Population genetics**: Hardy-Weinberg equilibrium, linkage disequilibrium\n2. **Inheritance patterns**: Mendelian ratios, segregation distortion\n3. **Distribution modeling**: Gene expression, mutation rates, species abundance\n4. **Model validation**: Checking assumptions in regression, ANOVA\n5. **Quality control**: Experimental design validation, batch effect detection\n6. **Evolutionary biology**: Neutral theory testing, selection detection\n:::\n\n### Python Implementation\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nfrom scipy.stats import chi2\n\n# Hardy-Weinberg equilibrium test\ndef hardy_weinberg_test(genotype_counts, alpha=0.05):\n    \"\"\"\n    Test Hardy-Weinberg equilibrium for a single gene with two alleles\n\n    Parameters:\n    genotype_counts: dict with keys 'AA', 'Aa', 'aa' and their counts\n    alpha: significance level\n\n    Returns:\n    dict with test results\n    \"\"\"\n    # Calculate total individuals and allele frequencies\n    total = sum(genotype_counts.values())\n\n    # Estimate allele frequencies\n    freq_A = (2 * genotype_counts['AA'] + genotype_counts['Aa']) / (2 * total)\n    freq_a = 1 - freq_A\n\n    # Expected genotype frequencies under HWE\n    expected_counts = {\n        'AA': freq_A**2 * total,\n        'Aa': 2 * freq_A * freq_a * total,\n        'aa': freq_a**2 * total\n    }\n\n    # Chi-squared test\n    observed = list(genotype_counts.values())\n    expected = list(expected_counts.values())\n\n    chi2_stat = sum((o - e)**2 / e for o, e in zip(observed, expected))\n    df = len(observed) - 1 - 1  # -1 for estimated parameter (allele freq)\n    p_value = 1 - chi2.cdf(chi2_stat, df)\n\n    return {\n        'chi2_statistic': chi2_stat,\n        'degrees_of_freedom': df,\n        'p_value': p_value,\n        'freq_A': freq_A,\n        'freq_a': freq_a,\n        'expected_counts': expected_counts,\n        'significant': p_value < alpha\n    }\n\n# Example usage\ngenotype_data = {'AA': 85, 'Aa': 435, 'aa': 480}\nhwe_result = hardy_weinberg_test(genotype_data)\n\nprint(\"Hardy-Weinberg Equilibrium Test Results:\")\nprint(f\"Chi-squared: {hwe_result['chi2_statistic']:.3f}\")\nprint(f\"p-value: {hwe_result['p_value']:.6f}\")\nprint(f\"A allele frequency: {hwe_result['freq_A']:.3f}\")\nprint(f\"a allele frequency: {hwe_result['freq_a']:.3f}\")\n\n# Mendelian ratio test\ndef mendelian_ratio_test(observed_counts, expected_ratio, alpha=0.05):\n    \"\"\"\n    Test observed counts against expected Mendelian ratio\n\n    Parameters:\n    observed_counts: list of observed counts\n    expected_ratio: list of expected ratios (e.g., [9, 3, 3, 1])\n    alpha: significance level\n\n    Returns:\n    dict with test results\n    \"\"\"\n    total_observed = sum(observed_counts)\n\n    # Calculate expected counts\n    total_ratio = sum(expected_ratio)\n    expected_counts = [(r / total_ratio) * total_observed for r in expected_ratio]\n\n    # Chi-squared test\n    chi2_stat = sum((o - e)**2 / e for o, e in zip(observed_counts, expected_counts))\n    df = len(observed_counts) - 1\n    p_value = 1 - chi2.cdf(chi2_stat, df)\n\n    return {\n        'chi2_statistic': chi2_stat,\n        'degrees_of_freedom': df,\n        'p_value': p_value,\n        'expected_counts': expected_counts,\n        'observed_ratio': [o / min(observed_counts) for o in observed_counts],\n        'significant': p_value < alpha\n    }\n\n# Example: Test 9:3:3:1 ratio\nf2_data = [315, 108, 101, 32]\nmendelian_result = mendelian_ratio_test(f2_data, [9, 3, 3, 1])\n\nprint(\"\\nMendelian Ratio Test (9:3:3:1):\")\nprint(f\"Chi-squared: {mendelian_result['chi2_statistic']:.3f}\")\nprint(f\"p-value: {mendelian_result['p_value']:.6f}\")\nprint(f\"Observed ratio: {[round(r, 1) for r in mendelian_result['observed_ratio']]}\")\n\n# Visualization\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n\n# HWE plot\ngenotypes = list(genotype_data.keys())\nobserved_hwe = list(genotype_data.values())\nexpected_hwe = list(hwe_result['expected_counts'].values())\n\nx = np.arange(len(genotypes))\nwidth = 0.35\n\nax1.bar(x - width/2, observed_hwe, width, label='Observed', alpha=0.7)\nax1.bar(x + width/2, expected_hwe, width, label='Expected (HWE)', alpha=0.7)\nax1.set_xlabel('Genotype')\nax1.set_ylabel('Count')\nax1.set_title('Hardy-Weinberg Equilibrium Test')\nax1.set_xticks(x)\nax1.set_xticklabels(genotypes)\nax1.legend()\n\n# Mendelian ratio plot\nphenotypes = ['Purple Round', 'Purple Wrinkled', 'Yellow Round', 'Yellow Wrinkled']\nobserved_mendel = f2_data\nexpected_mendel = mendelian_result['expected_counts']\n\nx = np.arange(len(phenotypes))\nax2.bar(x - width/2, observed_mendel, width, label='Observed', alpha=0.7)\nax2.bar(x + width/2, expected_mendel, width, label='Expected (9:3:3:1)', alpha=0.7)\nax2.set_xlabel('Phenotype')\nax2.set_ylabel('Count')\nax2.set_title('Mendelian Inheritance Test')\nax2.set_xticks(x)\nax2.set_xticklabels(phenotypes, rotation=45)\nax2.legend()\n\nplt.tight_layout()\nplt.show()\n```\n:::\n\n\n\n\n\n\n## Linear Regression in Biological Research\n\n### The Linear Model\n\nLinear regression models the relationship between predictor variables and an outcome, fundamental for understanding biological dose-response relationships, gene regulation, and biomarker associations.\n\n#### Simple Linear Regression\n\n$$Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i$$\n\nWhere:\n- $\\beta_0$: Intercept (baseline level when X = 0)\n- $\\beta_1$: Slope (change in Y per unit change in X)\n- $\\epsilon_i$: Random error term (biological variation)\n\n### Gene Expression Dose-Response Example\n\n#### Example 1: Drug Concentration vs Gene Expression\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate drug treatment experiment\nlibrary(ggplot2)\nlibrary(broom)\n\nset.seed(567)\nn_treatments <- 60\n\n# Drug concentrations (μM)\ndrug_concentration <- rep(c(0, 0.1, 0.5, 1, 5, 10), each = 10)\n\n# Target gene expression response (log2 fold change)\n# Includes biological variation and experimental noise\nbaseline_expression <- 0\nmax_response <- 3.5\nic50 <- 2  # Half-maximal concentration\n\n# Hill equation for dose-response (common in pharmacology)\ntheoretical_response <- baseline_expression +\n  (max_response * drug_concentration) / (ic50 + drug_concentration)\n\n# Add biological variation\nobserved_expression <- theoretical_response + rnorm(n_treatments, sd = 0.4)\n\n# Create dataset\ndrug_response_data <- data.frame(\n  Treatment_ID = 1:n_treatments,\n  Concentration_uM = drug_concentration,\n  Gene_Expression_FC = observed_expression,\n  log_Concentration = log10(drug_concentration + 0.01)  # Add small constant for log\n)\n\n# Fit linear regression\nlinear_model <- lm(Gene_Expression_FC ~ Concentration_uM, data = drug_response_data)\nlog_model <- lm(Gene_Expression_FC ~ log_Concentration, data = drug_response_data)\n\n# Model summaries\nsummary(linear_model)\nsummary(log_model)\n\n# Extract key statistics\nlinear_stats <- glance(linear_model)\nlog_stats <- glance(log_model)\n\ncat(\"Model Comparison:\\n\")\ncat(\"Linear model R² =\", round(linear_stats$r.squared, 3), \"\\n\")\ncat(\"Log model R² =\", round(log_stats$r.squared, 3), \"\\n\")\n\n# Visualization\np1 <- ggplot(drug_response_data, aes(x = Concentration_uM, y = Gene_Expression_FC)) +\n  geom_point(alpha = 0.7, size = 3, color = \"steelblue\") +\n  geom_smooth(method = \"lm\", color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Linear Model: Gene Expression vs Drug Concentration\",\n       x = \"Drug Concentration (μM)\", y = \"Gene Expression (log2 FC)\") +\n  theme_minimal()\n\np2 <- ggplot(drug_response_data, aes(x = log_Concentration, y = Gene_Expression_FC)) +\n  geom_point(alpha = 0.7, size = 3, color = \"darkgreen\") +\n  geom_smooth(method = \"lm\", color = \"red\", linetype = \"dashed\") +\n  labs(title = \"Log Model: Gene Expression vs log(Concentration)\",\n       x = \"log10(Concentration + 0.01)\", y = \"Gene Expression (log2 FC)\") +\n  theme_minimal()\n\nlibrary(patchwork)\nprint(p1 / p2)\n\n# Residual analysis\nresidual_data <- data.frame(\n  Fitted = fitted(linear_model),\n  Residuals = residuals(linear_model),\n  Concentration = drug_response_data$Concentration_uM\n)\n\nggplot(residual_data, aes(x = Fitted, y = Residuals)) +\n  geom_point(alpha = 0.7) +\n  geom_hline(yintercept = 0, linetype = \"dashed\", color = \"red\") +\n  geom_smooth(se = FALSE, color = \"blue\") +\n  labs(title = \"Residual Plot: Linear Model\",\n       x = \"Fitted Values\", y = \"Residuals\") +\n  theme_minimal()\n```\n:::\n\n\n\n\n\n\n#### Example 2: Tumor Size Prediction from Biomarkers\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate tumor biomarker data\nset.seed(678)\nn_tumors <- 100\n\n# Tumor characteristics\ntumor_age_weeks <- runif(n_tumors, min = 2, max = 20)  # Tumor age\nvascularization_score <- rnorm(n_tumors, mean = 5, sd = 1.5)  # 1-10 scale\n\n# Tumor volume (cm³) - depends on age and vascularization\n# Exponential growth modified by vascularization\nbase_growth_rate <- 0.15\nvolume <- exp(base_growth_rate * tumor_age_weeks +\n              0.1 * vascularization_score +\n              rnorm(n_tumors, sd = 0.3))\n\n# Log-transform for linear modeling\nlog_volume <- log(volume)\n\ntumor_growth_data <- data.frame(\n  Tumor_ID = paste0(\"Tumor_\", 1:n_tumors),\n  Age_weeks = tumor_age_weeks,\n  Vascularization = vascularization_score,\n  Volume_cm3 = volume,\n  log_Volume = log_volume\n)\n\n# Multiple regression model\ngrowth_model <- lm(log_Volume ~ Age_weeks + Vascularization, data = tumor_growth_data)\nsummary(growth_model)\n\n# Extract coefficients with confidence intervals\ncoef_summary <- tidy(growth_model, conf.int = TRUE)\nprint(coef_summary)\n\n# Biological interpretation\ncat(\"Biological Interpretation:\\n\")\ncat(\"Growth rate: Volume increases by\", round((exp(coef_summary$estimate[2]) - 1) * 100, 1),\n    \"% per week\\n\")\ncat(\"Vascularization effect: Each unit increase in vascularization score\\n\")\ncat(\"  increases volume by\", round((exp(coef_summary$estimate[3]) - 1) * 100, 1), \"%\\n\")\n\n# Model diagnostics\npar(mfrow = c(2, 2))\nplot(growth_model)\npar(mfrow = c(1, 1))\n\n# Prediction example\nnew_tumor <- data.frame(\n  Age_weeks = c(8, 12, 16),\n  Vascularization = c(4, 6, 8)\n)\n\npredictions <- predict(growth_model, new_tumor, interval = \"prediction\")\npred_volume <- exp(predictions)  # Back-transform from log scale\n\nprediction_results <- data.frame(\n  Age_weeks = new_tumor$Age_weeks,\n  Vascularization = new_tumor$Vascularization,\n  Predicted_Volume = pred_volume[, \"fit\"],\n  Lower_CI = pred_volume[, \"lwr\"],\n  Upper_CI = pred_volume[, \"upr\"]\n)\n\nprint(\"Tumor Volume Predictions:\")\nprint(round(prediction_results, 2))\n```\n:::\n\n\n\n\n\n\n### Multiple Linear Regression\n\n#### Example 3: Gene Expression Prediction from Multiple Factors\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate comprehensive gene regulation study\nset.seed(789)\nn_samples <- 120\n\n# Regulatory factors\ntranscription_factor_A <- rnorm(n_samples, mean = 6, sd = 1.2)  # TF-A expression\nchromatin_accessibility <- runif(n_samples, min = 0.2, max = 1.0)  # ATAC-seq score\ndna_methylation <- rbeta(n_samples, 2, 5)  # Beta distribution for methylation\nhistone_h3k4me3 <- rgamma(n_samples, shape = 3, scale = 1.5)  # Activating histone mark\n\n# Target gene expression (multiple regulatory inputs)\ntarget_gene_expression <-\n  2.0 +                                    # Baseline\n  0.8 * transcription_factor_A +           # TF binding effect\n  3.0 * chromatin_accessibility +          # Chromatin accessibility\n  -2.5 * dna_methylation +                 # Methylation repression\n  0.4 * histone_h3k4me3 +                  # Histone activation\n  0.3 * transcription_factor_A * chromatin_accessibility +  # Interaction\n  rnorm(n_samples, sd = 0.8)              # Biological noise\n\ngene_regulation_data <- data.frame(\n  Sample_ID = paste0(\"Sample_\", 1:n_samples),\n  TF_A_expression = transcription_factor_A,\n  Chromatin_access = chromatin_accessibility,\n  DNA_methylation = dna_methylation,\n  H3K4me3_signal = histone_h3k4me3,\n  Target_gene = target_gene_expression\n)\n\n# Fit multiple regression models\n# Model 1: Main effects only\nmodel_main <- lm(Target_gene ~ TF_A_expression + Chromatin_access +\n                 DNA_methylation + H3K4me3_signal,\n                 data = gene_regulation_data)\n\n# Model 2: Include interaction\nmodel_interaction <- lm(Target_gene ~ TF_A_expression + Chromatin_access +\n                       DNA_methylation + H3K4me3_signal +\n                       TF_A_expression:Chromatin_access,\n                       data = gene_regulation_data)\n\n# Compare models\nanova(model_main, model_interaction)\nsummary(model_interaction)\n\n# Calculate standardized coefficients (beta coefficients)\nlibrary(car)\nstandardized_coefs <- data.frame(\n  Variable = names(coef(model_interaction))[-1],  # Exclude intercept\n  Standardized_Beta = scale(model.matrix(model_interaction)[, -1]) %*%\n                     coef(model_interaction)[-1] / sd(gene_regulation_data$Target_gene)\n)\n\ncat(\"Standardized coefficients (relative importance):\\n\")\nprint(standardized_coefs[order(-abs(standardized_coefs$Standardized_Beta)), ])\n\n# Model performance metrics\nmodel_performance <- data.frame(\n  Model = c(\"Main Effects\", \"With Interaction\"),\n  R_squared = c(summary(model_main)$r.squared, summary(model_interaction)$r.squared),\n  Adj_R_squared = c(summary(model_main)$adj.r.squared, summary(model_interaction)$adj.r.squared),\n  AIC = c(AIC(model_main), AIC(model_interaction)),\n  BIC = c(BIC(model_main), BIC(model_interaction))\n)\n\nprint(\"Model Comparison:\")\nprint(round(model_performance, 3))\n\n# Visualization of key relationships\np1 <- ggplot(gene_regulation_data, aes(x = TF_A_expression, y = Target_gene,\n                                      color = Chromatin_access)) +\n  geom_point(alpha = 0.7) +\n  scale_color_gradient(low = \"red\", high = \"blue\", name = \"Chromatin\\nAccess\") +\n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\") +\n  labs(title = \"TF-A vs Target Gene (colored by chromatin accessibility)\",\n       x = \"TF-A Expression\", y = \"Target Gene Expression\") +\n  theme_minimal()\n\np2 <- ggplot(gene_regulation_data, aes(x = DNA_methylation, y = Target_gene)) +\n  geom_point(alpha = 0.7, color = \"darkred\") +\n  geom_smooth(method = \"lm\", color = \"black\") +\n  labs(title = \"DNA Methylation vs Target Gene\",\n       x = \"DNA Methylation Level\", y = \"Target Gene Expression\") +\n  theme_minimal()\n\nprint(p1 / p2)\n\n# Interaction plot\nlibrary(interactions)\ninteract_plot(model_interaction, pred = TF_A_expression, modx = Chromatin_access,\n             plot.points = TRUE, point.alpha = 0.5,\n             main.title = \"TF-A × Chromatin Accessibility Interaction\")\n```\n:::\n\n\n\n\n\n\n### Regression Assumptions and Diagnostics\n\n#### Checking Model Assumptions in Biological Data\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(performance)\nlibrary(see)\n\n# Comprehensive model diagnostics\ncheck_model(model_interaction)\n\n# Individual assumption checks\ncat(\"Linearity Check:\\n\")\ncheck_linearity(model_interaction)\n\ncat(\"\\nHomoscedasticity Check:\\n\")\ncheck_heteroscedasticity(model_interaction)\n\ncat(\"\\nNormality of Residuals:\\n\")\ncheck_normality(model_interaction)\n\ncat(\"\\nCollinearity Check:\\n\")\ncheck_collinearity(model_interaction)\n\n# Outlier detection\noutliers <- check_outliers(model_interaction)\nprint(outliers)\n\n# Cook's distance for influential points\ncooks_d <- cooks.distance(model_interaction)\ninfluential_samples <- which(cooks_d > 4/n_samples)\n\nif(length(influential_samples) > 0) {\n  cat(\"Influential samples (high Cook's distance):\\n\")\n  print(gene_regulation_data[influential_samples, c(\"Sample_ID\", \"Target_gene\")])\n}\n```\n:::\n\n\n\n\n\n\n### Advanced Regression Techniques\n\n#### Robust Regression for Outlier-Resistant Analysis\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\n\n# Fit robust regression (less sensitive to outliers)\nrobust_model <- rlm(Target_gene ~ TF_A_expression + Chromatin_access +\n                   DNA_methylation + H3K4me3_signal,\n                   data = gene_regulation_data)\n\n# Compare standard vs robust regression\ncomparison_coefs <- data.frame(\n  Variable = names(coef(model_main)),\n  Standard_LM = coef(model_main),\n  Robust_LM = coef(robust_model),\n  Difference = coef(model_main) - coef(robust_model)\n)\n\nprint(\"Standard vs Robust Regression Coefficients:\")\nprint(round(comparison_coefs, 3))\n\n# Identify samples with different weights in robust regression\nsample_weights <- robust_model$w\nlow_weight_samples <- which(sample_weights < 0.8)\n\ncat(\"Samples with reduced weight in robust regression (potential outliers):\\n\")\nif(length(low_weight_samples) > 0) {\n  print(gene_regulation_data[low_weight_samples,\n                            c(\"Sample_ID\", \"Target_gene\", \"TF_A_expression\")])\n}\n```\n:::\n\n\n\n\n\n\n## Logistic Regression for Classification\n\n### When to Use Logistic Regression\n\nLogistic regression is essential for binary classification problems in biology:\n- Disease diagnosis (positive/negative)\n- Treatment response (responder/non-responder)\n- Gene function prediction (essential/non-essential)\n- Tumor classification (malignant/benign)\n- Survival outcomes (survived/died)\n\n### The Logistic Model\n\nInstead of predicting the outcome directly, logistic regression predicts the log-odds:\n\n$$\\text{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_k X_k$$\n\nWhere $p$ is the probability of the event occurring.\n\nThe probability is then:\n\n$$p = \\frac{e^{\\beta_0 + \\beta_1 X_1 + ... + \\beta_k X_k}}{1 + e^{\\beta_0 + \\beta_1 X_1 + ... + \\beta_k X_k}}$$\n\n### Tumor Classification Examples\n\n#### Example 1: Malignant vs Benign Tumor Classification\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate tumor classification data\nlibrary(ggplot2)\nlibrary(pROC)\nlibrary(caret)\n\nset.seed(890)\nn_tumors <- 300\n\n# Tumor characteristics\ntumor_size <- rexp(n_tumors, rate = 1.5)  # Exponential distribution\ncell_density <- rnorm(n_tumors, mean = 1000, sd = 300)  # cells per mm²\nvascularity_score <- rgamma(n_tumors, shape = 2, scale = 3)  # 0-15 scale\nki67_index <- rbeta(n_tumors, 2, 8) * 100  # 0-100% proliferation\nnuclear_atypia <- sample(1:4, n_tumors, replace = TRUE, prob = c(0.4, 0.3, 0.2, 0.1))\n\n# Create malignancy probability based on biological factors\nlogit_malignant <- -3 +\n  0.8 * tumor_size +                    # Larger tumors more likely malignant\n  0.002 * cell_density +                # Higher density increases risk\n  0.15 * vascularity_score +            # High vascularity suspicious\n  0.04 * ki67_index +                   # High proliferation index\n  0.6 * nuclear_atypia                  # Nuclear atypia strongly predictive\n\nprob_malignant <- plogis(logit_malignant)  # Convert to probability\nmalignant <- rbinom(n_tumors, 1, prob_malignant)\n\n# Create dataset\ntumor_classification_data <- data.frame(\n  Tumor_ID = paste0(\"T\", sprintf(\"%03d\", 1:n_tumors)),\n  Size_cm = tumor_size,\n  Cell_Density = cell_density,\n  Vascularity = vascularity_score,\n  Ki67_Index = ki67_index,\n  Nuclear_Atypia = factor(nuclear_atypia, labels = c(\"None\", \"Mild\", \"Moderate\", \"Severe\")),\n  Malignant = factor(malignant, labels = c(\"Benign\", \"Malignant\"))\n)\n\n# Fit logistic regression model\nmalignancy_model <- glm(Malignant ~ Size_cm + Cell_Density + Vascularity +\n                       Ki67_Index + Nuclear_Atypia,\n                       family = binomial, data = tumor_classification_data)\n\nsummary(malignancy_model)\n\n# Calculate odds ratios with confidence intervals\nodds_ratios <- exp(cbind(coef(malignancy_model), confint(malignancy_model)))\ncolnames(odds_ratios) <- c(\"Odds_Ratio\", \"CI_Lower\", \"CI_Upper\")\n\ncat(\"Odds Ratios and 95% Confidence Intervals:\\n\")\nprint(round(odds_ratios, 3))\n\n# Model predictions\ntumor_classification_data$predicted_prob <- predict(malignancy_model, type = \"response\")\ntumor_classification_data$predicted_class <- ifelse(tumor_classification_data$predicted_prob > 0.5,\n                                                   \"Malignant\", \"Benign\")\n\n# Model performance evaluation\nconf_matrix <- confusionMatrix(\n  factor(tumor_classification_data$predicted_class, levels = c(\"Benign\", \"Malignant\")),\n  tumor_classification_data$Malignant\n)\n\nprint(conf_matrix)\n\n# ROC curve analysis\nroc_curve <- roc(malignant, tumor_classification_data$predicted_prob)\nauc_value <- auc(roc_curve)\n\ncat(\"AUC =\", round(auc_value, 3), \"\\n\")\n\n# Plot ROC curve\nggroc(roc_curve, color = \"blue\", size = 1) +\n  geom_abline(intercept = 1, slope = 1, linetype = \"dashed\", color = \"red\") +\n  labs(title = paste(\"ROC Curve: Tumor Malignancy Classification (AUC =\", round(auc_value, 3), \")\"),\n       x = \"1 - Specificity (False Positive Rate)\",\n       y = \"Sensitivity (True Positive Rate)\") +\n  theme_minimal()\n\n# Feature importance visualization\ncoef_data <- data.frame(\n  Feature = names(coef(malignancy_model))[-1],  # Exclude intercept\n  Coefficient = coef(malignancy_model)[-1],\n  Odds_Ratio = exp(coef(malignancy_model)[-1])\n)\n\nggplot(coef_data, aes(x = reorder(Feature, Coefficient), y = Coefficient)) +\n  geom_col(fill = \"steelblue\", alpha = 0.7) +\n  geom_hline(yintercept = 0, linetype = \"dashed\") +\n  coord_flip() +\n  labs(title = \"Logistic Regression Coefficients\",\n       subtitle = \"Positive coefficients increase malignancy probability\",\n       x = \"Features\", y = \"Coefficient\") +\n  theme_minimal()\n```\n:::\n\n\n\n\n\n\n#### Example 2: Gene Expression-Based Cancer Subtype Classification\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate gene expression-based cancer classification\nset.seed(991)\nn_patients <- 250\n\n# Simulate expression of key cancer genes\n# ER (Estrogen Receptor) - high in hormone-positive cancers\ner_expression <- c(rnorm(125, mean = 8, sd = 1.2),    # High ER group\n                   rnorm(125, mean = 3, sd = 1.0))    # Low ER group\n\n# HER2 - amplified in ~20% of breast cancers\nher2_amplified <- sample(c(0, 1), n_patients, replace = TRUE, prob = c(0.8, 0.2))\nher2_expression <- ifelse(her2_amplified, rnorm(sum(her2_amplified), 9, 1),\n                         rnorm(n_patients - sum(her2_amplified), 4, 1))\n\n# TP53 mutation signature (composite score)\ntp53_signature <- rnorm(n_patients, mean = 5, sd = 1.5)\n\n# Proliferation signature (cell cycle genes)\nprolif_signature <- rgamma(n_patients, shape = 3, scale = 2)\n\n# Immune signature\nimmune_signature <- rbeta(n_patients, 2, 2) * 10\n\n# Define cancer subtypes based on expression patterns\n# Luminal A: ER+, HER2-, low proliferation\n# Luminal B: ER+, HER2+/-, high proliferation\n# HER2+: ER-, HER2+\n# Triple Negative: ER-, HER2-, often high TP53 signature\n\nsubtype_prob_lumA <- plogis(-2 + 0.8 * er_expression - 2 * her2_amplified - 0.3 * prolif_signature)\nsubtype_prob_lumB <- plogis(-3 + 0.6 * er_expression + 0.5 * prolif_signature)\nsubtype_prob_her2 <- plogis(-4 + 3 * her2_amplified - 0.5 * er_expression)\n\n# Assign subtypes (simplified logic)\ncancer_subtype <- character(n_patients)\nfor(i in 1:n_patients) {\n  probs <- c(subtype_prob_lumA[i], subtype_prob_lumB[i], subtype_prob_her2[i])\n  if(er_expression[i] > 6 & her2_amplified[i] == 0 & prolif_signature[i] < 4) {\n    cancer_subtype[i] <- \"Luminal_A\"\n  } else if(er_expression[i] > 6 & prolif_signature[i] >= 4) {\n    cancer_subtype[i] <- \"Luminal_B\"\n  } else if(her2_amplified[i] == 1) {\n    cancer_subtype[i] <- \"HER2_Positive\"\n  } else {\n    cancer_subtype[i] <- \"Triple_Negative\"\n  }\n}\n\n# Create gene expression dataset\ngene_expression_data <- data.frame(\n  Patient_ID = paste0(\"P\", sprintf(\"%03d\", 1:n_patients)),\n  ER_Expression = er_expression,\n  HER2_Expression = her2_expression,\n  HER2_Amplified = factor(her2_amplified),\n  TP53_Signature = tp53_signature,\n  Proliferation_Signature = prolif_signature,\n  Immune_Signature = immune_signature,\n  Cancer_Subtype = factor(cancer_subtype)\n)\n\n# Split data for training and testing\nset.seed(123)\ntrain_indices <- createDataPartition(gene_expression_data$Cancer_Subtype, p = 0.7, list = FALSE)\ntrain_data <- gene_expression_data[train_indices, ]\ntest_data <- gene_expression_data[-train_indices, ]\n\n# Train multinomial logistic regression for multi-class classification\nlibrary(nnet)\nmultinomial_model <- multinom(Cancer_Subtype ~ ER_Expression + HER2_Expression +\n                             TP53_Signature + Proliferation_Signature + Immune_Signature,\n                             data = train_data, trace = FALSE)\n\nsummary(multinomial_model)\n\n# Make predictions\ntrain_predictions <- predict(multinomial_model, train_data)\ntest_predictions <- predict(multinomial_model, test_data)\n\n# Training performance\ntrain_confusion <- confusionMatrix(train_predictions, train_data$Cancer_Subtype)\nprint(\"Training Set Performance:\")\nprint(train_confusion)\n\n# Test performance\ntest_confusion <- confusionMatrix(test_predictions, test_data$Cancer_Subtype)\nprint(\"Test Set Performance:\")\nprint(test_confusion)\n\n# Prediction probabilities for each class\ntest_probs <- predict(multinomial_model, test_data, type = \"probs\")\ntest_data_with_probs <- cbind(test_data, test_probs)\n\n# Visualize prediction confidence\nlibrary(reshape2)\nprob_data <- melt(test_data_with_probs[, c(\"Patient_ID\", \"Cancer_Subtype\",\n                                          \"Luminal_A\", \"Luminal_B\", \"HER2_Positive\", \"Triple_Negative\")],\n                 id.vars = c(\"Patient_ID\", \"Cancer_Subtype\"),\n                 variable.name = \"Predicted_Subtype\", value.name = \"Probability\")\n\nggplot(prob_data, aes(x = Cancer_Subtype, y = Probability, fill = Predicted_Subtype)) +\n  geom_boxplot(alpha = 0.7) +\n  facet_wrap(~ Predicted_Subtype, nrow = 2) +\n  labs(title = \"Prediction Probabilities by True Cancer Subtype\",\n       x = \"True Subtype\", y = \"Predicted Probability\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n:::\n\n\n\n\n\n\n### Advanced Classification Techniques\n\n#### Example 3: Random Forest for Gene Expression Classification\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(randomForest)\nlibrary(ROCR)\n\n# Train Random Forest model for comparison\nrf_model <- randomForest(Cancer_Subtype ~ ER_Expression + HER2_Expression +\n                        TP53_Signature + Proliferation_Signature + Immune_Signature,\n                        data = train_data, ntree = 500, importance = TRUE)\n\nprint(rf_model)\n\n# Variable importance\nimportance_scores <- importance(rf_model)\nimportance_df <- data.frame(\n  Gene = rownames(importance_scores),\n  Mean_Decrease_Accuracy = importance_scores[, \"MeanDecreaseAccuracy\"],\n  Mean_Decrease_Gini = importance_scores[, \"MeanDecreaseGini\"]\n)\n\nggplot(importance_df, aes(x = reorder(Gene, Mean_Decrease_Accuracy),\n                         y = Mean_Decrease_Accuracy)) +\n  geom_col(fill = \"darkgreen\", alpha = 0.7) +\n  coord_flip() +\n  labs(title = \"Gene Importance in Cancer Subtype Classification\",\n       x = \"Genes\", y = \"Mean Decrease in Accuracy\") +\n  theme_minimal()\n\n# Random Forest predictions\nrf_test_predictions <- predict(rf_model, test_data)\nrf_test_confusion <- confusionMatrix(rf_test_predictions, test_data$Cancer_Subtype)\n\nprint(\"Random Forest Test Performance:\")\nprint(rf_test_confusion)\n\n# Compare model performances\nmodel_comparison <- data.frame(\n  Model = c(\"Multinomial Logistic\", \"Random Forest\"),\n  Accuracy = c(test_confusion$overall[\"Accuracy\"],\n               rf_test_confusion$overall[\"Accuracy\"]),\n  Kappa = c(test_confusion$overall[\"Kappa\"],\n            rf_test_confusion$overall[\"Kappa\"])\n)\n\nprint(\"Model Comparison:\")\nprint(round(model_comparison, 3))\n```\n:::\n\n\n\n\n\n\n### Biomarker Discovery and Validation\n\n#### Example 4: Protein Biomarker Panel for Early Cancer Detection\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate protein biomarker discovery study\nset.seed(1001)\nn_controls <- 150\nn_cases <- 100\n\n# Simulate protein abundance levels (log-transformed)\n# 10 proteins measured, 3 are true biomarkers\n\n# Control samples\ncontrol_proteins <- matrix(rnorm(n_controls * 10, mean = 5, sd = 1),\n                          nrow = n_controls, ncol = 10)\n\n# Case samples - biomarkers 1, 3, 7 are elevated\ncase_proteins <- matrix(rnorm(n_cases * 10, mean = 5, sd = 1),\n                       nrow = n_cases, ncol = 10)\n\n# Add signal to true biomarkers\ncase_proteins[, 1] <- rnorm(n_cases, mean = 6.5, sd = 1.2)  # Protein 1: strong signal\ncase_proteins[, 3] <- rnorm(n_cases, mean = 6.0, sd = 1.1)  # Protein 3: moderate signal\ncase_proteins[, 7] <- rnorm(n_cases, mean = 5.8, sd = 1.0)  # Protein 7: weak signal\n\n# Combine data\nall_proteins <- rbind(control_proteins, case_proteins)\ncancer_status <- c(rep(0, n_controls), rep(1, n_cases))\n\nprotein_names <- paste0(\"Protein_\", LETTERS[1:10])\ncolnames(all_proteins) <- protein_names\n\nbiomarker_data <- data.frame(\n  Sample_ID = paste0(\"S\", sprintf(\"%03d\", 1:(n_controls + n_cases))),\n  Cancer = factor(cancer_status, labels = c(\"Control\", \"Cancer\")),\n  all_proteins\n)\n\n# Split into discovery and validation sets\ndiscovery_indices <- sample(1:nrow(biomarker_data), size = 0.6 * nrow(biomarker_data))\ndiscovery_set <- biomarker_data[discovery_indices, ]\nvalidation_set <- biomarker_data[-discovery_indices, ]\n\n# Univariate analysis to identify candidate biomarkers\nunivariate_results <- data.frame(\n  Protein = protein_names,\n  AUC = numeric(10),\n  P_value = numeric(10)\n)\n\nfor(i in 1:10) {\n  protein_col <- paste0(\"Protein_\", LETTERS[i])\n\n  # Logistic regression\n  model <- glm(Cancer ~ get(protein_col), data = discovery_set, family = binomial)\n  p_val <- summary(model)$coefficients[2, 4]\n\n  # ROC analysis\n  roc_obj <- roc(discovery_set$Cancer, discovery_set[[protein_col]])\n  auc_val <- as.numeric(auc(roc_obj))\n\n  univariate_results[i, \"AUC\"] <- auc_val\n  univariate_results[i, \"P_value\"] <- p_val\n}\n\n# Adjust p-values for multiple testing\nunivariate_results$Adj_P_value <- p.adjust(univariate_results$P_value, method = \"BH\")\n\ncat(\"Univariate Biomarker Analysis (Discovery Set):\\n\")\nprint(univariate_results[order(-univariate_results$AUC), ])\n\n# Select top biomarkers for panel (AUC > 0.7 and adj p < 0.05)\nselected_biomarkers <- univariate_results[\n  univariate_results$AUC > 0.7 & univariate_results$Adj_P_value < 0.05, \"Protein\"\n]\n\ncat(\"Selected biomarkers for panel:\", paste(selected_biomarkers, collapse = \", \"), \"\\n\")\n\n# Build multivariate model with selected biomarkers\npanel_formula <- as.formula(paste(\"Cancer ~\", paste(selected_biomarkers, collapse = \" + \")))\npanel_model <- glm(panel_formula, data = discovery_set, family = binomial)\n\nsummary(panel_model)\n\n# Validate panel performance\n# Discovery set performance\ndiscovery_probs <- predict(panel_model, discovery_set, type = \"response\")\ndiscovery_roc <- roc(discovery_set$Cancer, discovery_probs)\n\n# Validation set performance\nvalidation_probs <- predict(panel_model, validation_set, type = \"response\")\nvalidation_roc <- roc(validation_set$Cancer, validation_probs)\n\ncat(\"Biomarker Panel Performance:\\n\")\ncat(\"Discovery AUC:\", round(auc(discovery_roc), 3), \"\\n\")\ncat(\"Validation AUC:\", round(auc(validation_roc), 3), \"\\n\")\n\n# Plot ROC curves\nlibrary(patchwork)\np1 <- ggroc(discovery_roc, color = \"blue\") +\n  geom_abline(intercept = 1, slope = 1, linetype = \"dashed\") +\n  labs(title = paste(\"Discovery Set (AUC =\", round(auc(discovery_roc), 3), \")\")) +\n  theme_minimal()\n\np2 <- ggroc(validation_roc, color = \"red\") +\n  geom_abline(intercept = 1, slope = 1, linetype = \"dashed\") +\n  labs(title = paste(\"Validation Set (AUC =\", round(auc(validation_roc), 3), \")\")) +\n  theme_minimal()\n\nprint(p1 | p2)\n\n# Biomarker panel score distribution\nvalidation_set$Panel_Score <- validation_probs\n\nggplot(validation_set, aes(x = Cancer, y = Panel_Score, fill = Cancer)) +\n  geom_boxplot(alpha = 0.7) +\n  geom_jitter(width = 0.2, alpha = 0.5) +\n  scale_fill_manual(values = c(\"lightblue\", \"lightcoral\")) +\n  labs(title = \"Biomarker Panel Score Distribution\",\n       x = \"Cancer Status\", y = \"Panel Score (Probability)\") +\n  theme_minimal()\n\n# Optimal cutoff selection\noptimal_cutoff <- coords(validation_roc, \"best\", ret = \"threshold\")\nsensitivity_at_cutoff <- coords(validation_roc, optimal_cutoff, ret = \"sensitivity\")\nspecificity_at_cutoff <- coords(validation_roc, optimal_cutoff, ret = \"specificity\")\n\ncat(\"Optimal cutoff:\", round(optimal_cutoff, 3), \"\\n\")\ncat(\"Sensitivity:\", round(sensitivity_at_cutoff, 3), \"\\n\")\ncat(\"Specificity:\", round(specificity_at_cutoff, 3), \"\\n\")\n```\n:::\n\n\n\n\n\n\n::: {.callout-note}\n## Key Principles for Biological Classification Models\n\n1. **Feature selection** is crucial - not all measured variables are informative\n2. **Cross-validation** prevents overfitting, especially with high-dimensional data\n3. **Independent validation** is essential for clinical biomarker development\n4. **Biological interpretation** should guide model selection and feature engineering\n5. **Multiple testing correction** is critical when screening many potential biomarkers\n6. **Clinical context** determines optimal sensitivity/specificity trade-offs\n:::\n\n### Model Selection and Validation Strategies\n\n#### Cross-Validation for Robust Performance Estimation\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n\n# 10-fold cross-validation for biomarker panel\nset.seed(1111)\n\n# Define training control\ntrain_control <- trainControl(\n  method = \"cv\",\n  number = 10,\n  summaryFunction = twoClassSummary,\n  classProbs = TRUE,\n  savePredictions = TRUE\n)\n\n# Train model with cross-validation\ncv_model <- train(\n  panel_formula,\n  data = discovery_set,\n  method = \"glm\",\n  family = \"binomial\",\n  trControl = train_control,\n  metric = \"ROC\"\n)\n\nprint(cv_model)\n\n# Cross-validation performance\ncv_auc <- cv_model$results$ROC\ncv_sensitivity <- cv_model$results$Sens\ncv_specificity <- cv_model$results$Spec\n\ncat(\"Cross-Validation Results:\\n\")\ncat(\"Mean AUC:\", round(cv_auc, 3), \"\\n\")\ncat(\"Mean Sensitivity:\", round(cv_sensitivity, 3), \"\\n\")\ncat(\"Mean Specificity:\", round(cv_specificity, 3), \"\\n\")\n\n# Plot cross-validation predictions\ncv_predictions <- cv_model$pred\nggplot(cv_predictions, aes(x = obs, y = Cancer, fill = obs)) +\n  geom_boxplot(alpha = 0.7) +\n  labs(title = \"Cross-Validation Predictions\",\n       x = \"Observed Class\", y = \"Predicted Probability\") +\n  theme_minimal()\n```\n:::\n\n\n\n\n\n\n## Model Evaluation for Classification\n\n### The Confusion Matrix\n\nA confusion matrix is a table that shows how well our classification model performs. It's like a report card for prediction models.\n\n::: {.callout-note}\n## Think of it this way\nImagine you're a doctor using a test to diagnose disease. The confusion matrix shows:\n- How many sick patients you correctly identified (True Positives)\n- How many healthy patients you correctly identified (True Negatives)\n- How many times you missed the disease (False Negatives)\n- How many times you incorrectly diagnosed disease (False Positives)\n:::\n\n### 2×2 Confusion Matrix\n\n|                | **Predicted** |           |\n|----------------|:-------------:|:---------:|\n| **Actual**     | **Positive**  | **Negative** |\n| **Positive**   | TP            | FN        |\n| **Negative**   | FP            | TN        |\n\nWhere:\n- **TP (True Positives)**: Correctly predicted positive cases\n- **TN (True Negatives)**: Correctly predicted negative cases\n- **FP (False Positives)**: Incorrectly predicted positive (Type I error)\n- **FN (False Negatives)**: Incorrectly predicted negative (Type II error)\n\n### Example: COVID-19 Test Evaluation\n\nLet's say we have a COVID-19 test and we tested 1000 people:\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create confusion matrix data\nlibrary(caret)\n\n# Simulate COVID test results\nset.seed(789)\nn <- 1000\ntrue_status <- c(rep(\"Positive\", 100), rep(\"Negative\", 900))  # 10% prevalence\ntest_sensitivity <- 0.95  # 95% of positive cases detected\ntest_specificity <- 0.98  # 98% of negative cases correctly identified\n\npredicted_status <- ifelse(\n  true_status == \"Positive\",\n  ifelse(runif(sum(true_status == \"Positive\")) < test_sensitivity, \"Positive\", \"Negative\"),\n  ifelse(runif(sum(true_status == \"Negative\")) < test_specificity, \"Negative\", \"Positive\")\n)\n\n# Create confusion matrix\ncm <- confusionMatrix(as.factor(predicted_status), as.factor(true_status), positive = \"Positive\")\nprint(cm)\n\n# Visualize confusion matrix\nlibrary(ggplot2)\ncm_table <- as.data.frame(cm$table)\nggplot(cm_table, aes(x = Reference, y = Prediction, fill = Freq)) +\n  geom_tile(color = \"white\") +\n  geom_text(aes(label = Freq), size = 12, color = \"white\") +\n  scale_fill_gradient(low = \"lightblue\", high = \"darkblue\") +\n  labs(title = \"COVID-19 Test Confusion Matrix\",\n       x = \"Actual Status\", y = \"Predicted Status\") +\n  theme_minimal() +\n  theme(text = element_text(size = 12))\n```\n:::\n\n\n\n\n\n\n## Diagnostic Test Performance Metrics\n\nFrom the confusion matrix, we can calculate several important metrics:\n\n### Sensitivity (True Positive Rate)\n\n**What it means**: Of all the people who actually have the disease, what percentage does our test catch?\n\n$$\\text{Sensitivity} = \\frac{TP}{TP + FN}$$\n\n**Example**: If sensitivity = 0.95, then our test catches 95% of COVID-positive patients.\n\n### Specificity (True Negative Rate)\n\n**What it means**: Of all the people who don't have the disease, what percentage does our test correctly identify as negative?\n\n$$\\text{Specificity} = \\frac{TN}{TN + FP}$$\n\n**Example**: If specificity = 0.98, then our test correctly identifies 98% of COVID-negative patients.\n\n### Positive Predictive Value (PPV)\n\n**What it means**: If the test is positive, what's the probability the person actually has the disease?\n\n$$\\text{PPV} = \\frac{TP}{TP + FP}$$\n\n### Negative Predictive Value (NPV)\n\n**What it means**: If the test is negative, what's the probability the person actually doesn't have the disease?\n\n$$\\text{NPV} = \\frac{TN}{TN + FN}$$\n\n::: {.callout-warning}\n## Important: PPV and NPV depend on disease prevalence!\nIn a population where disease is rare, even a good test will have many false positives, lowering PPV. In a high-prevalence population, the same test will have better PPV.\n:::\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate metrics manually\ncalculate_metrics <- function(tp, tn, fp, fn) {\n  sensitivity <- tp / (tp + fn)\n  specificity <- tn / (tn + fp)\n  ppv <- tp / (tp + fp)\n  npv <- tn / (tn + fn)\n  accuracy <- (tp + tn) / (tp + tn + fp + fn)\n\n  return(list(\n    Sensitivity = sensitivity,\n    Specificity = specificity,\n    PPV = ppv,\n    NPV = npv,\n    Accuracy = accuracy\n  ))\n}\n\n# Example with our COVID data\nmetrics <- calculate_metrics(tp = 95, tn = 882, fp = 18, fn = 5)\nprint(metrics)\n```\n:::\n\n\n\n\n\n\n## ROC Curves and AUC\n\n### What is an ROC Curve?\n\nROC stands for \"Receiver Operating Characteristic.\" Think of it as a way to visualize the trade-off between catching true cases (sensitivity) and avoiding false alarms (1 - specificity).\n\n**Real-world analogy**: Imagine you're a security guard with a metal detector. You can adjust the sensitivity:\n- High sensitivity: Catches all weapons but sets off many false alarms\n- Low sensitivity: Fewer false alarms but might miss some weapons\n\nThe ROC curve shows this trade-off at different threshold settings.\n\n### Mathematical Definition\n\nThe ROC curve plots:\n- **Y-axis**: True Positive Rate (Sensitivity) = $\\frac{TP}{TP + FN}$\n- **X-axis**: False Positive Rate (1 - Specificity) = $\\frac{FP}{FP + TN}$\n\n### Creating ROC Curves\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pROC)\nlibrary(ggplot2)\n\n# Simulate biomarker data for disease diagnosis\nset.seed(101)\nn_healthy <- 500\nn_diseased <- 200\n\n# Healthy individuals: lower biomarker levels\nhealthy_biomarker <- rnorm(n_healthy, mean = 10, sd = 3)\n\n# Diseased individuals: higher biomarker levels\ndiseased_biomarker <- rnorm(n_diseased, mean = 15, sd = 3)\n\n# Combine data\nbiomarker_values <- c(healthy_biomarker, diseased_biomarker)\ntrue_status <- c(rep(0, n_healthy), rep(1, n_diseased))\n\n# Create ROC curve\nroc_obj <- roc(true_status, biomarker_values)\n\n# Plot ROC curve\nggroc(roc_obj, color = \"blue\", size = 1) +\n  geom_abline(intercept = 1, slope = 1, linetype = \"dashed\", color = \"red\") +\n  labs(title = \"ROC Curve for Biomarker Test\",\n       x = \"False Positive Rate (1 - Specificity)\",\n       y = \"True Positive Rate (Sensitivity)\") +\n  theme_minimal() +\n  annotate(\"text\", x = 0.7, y = 0.3,\n           label = paste(\"AUC =\", round(auc(roc_obj), 3)), size = 5)\n```\n:::\n\n\n\n\n\n\n### Understanding AUC (Area Under the Curve)\n\nThe AUC summarizes the ROC curve into a single number between 0 and 1:\n\n$$\\text{AUC} = \\int_0^1 \\text{TPR}(t) \\, d(\\text{FPR}(t))$$\n\n**Interpretation**:\n- **AUC = 0.5**: Random guessing (coin flip)\n- **AUC = 0.7**: Acceptable discrimination\n- **AUC = 0.8**: Excellent discrimination\n- **AUC = 0.9**: Outstanding discrimination\n- **AUC = 1.0**: Perfect discrimination\n\n::: {.callout-tip}\n## Intuitive AUC Interpretation\nAUC represents the probability that a randomly selected positive case will have a higher predicted probability than a randomly selected negative case.\n\nIf AUC = 0.8, then 80% of the time, a diseased person will have a higher biomarker value than a healthy person.\n:::\n\n### Comparing Multiple Tests\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Simulate three different biomarkers\nbiomarker1 <- c(rnorm(n_healthy, 10, 3), rnorm(n_diseased, 15, 3))  # Good test\nbiomarker2 <- c(rnorm(n_healthy, 12, 4), rnorm(n_diseased, 14, 4))  # Moderate test\nbiomarker3 <- c(rnorm(n_healthy, 11, 5), rnorm(n_diseased, 13, 5))  # Poor test\n\n# Create ROC curves\nroc1 <- roc(true_status, biomarker1)\nroc2 <- roc(true_status, biomarker2)\nroc3 <- roc(true_status, biomarker3)\n\n# Plot comparison\nlibrary(patchwork)\np1 <- ggroc(list(\"Biomarker 1\" = roc1, \"Biomarker 2\" = roc2, \"Biomarker 3\" = roc3)) +\n  scale_color_manual(values = c(\"blue\", \"green\", \"red\")) +\n  geom_abline(intercept = 1, slope = 1, linetype = \"dashed\", color = \"black\") +\n  labs(title = \"Comparison of Three Biomarkers\",\n       x = \"False Positive Rate\", y = \"True Positive Rate\") +\n  theme_minimal()\n\n# Print AUC values\ncat(\"AUC Values:\\n\")\ncat(\"Biomarker 1:\", round(auc(roc1), 3), \"\\n\")\ncat(\"Biomarker 2:\", round(auc(roc2), 3), \"\\n\")\ncat(\"Biomarker 3:\", round(auc(roc3), 3), \"\\n\")\n\nprint(p1)\n```\n:::\n\n\n\n\n\n\n### Optimal Threshold Selection\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Find optimal threshold using Youden's J statistic\ncoords_all <- coords(roc1, \"all\", ret = c(\"threshold\", \"sensitivity\", \"specificity\"))\ncoords_all$youden <- coords_all$sensitivity + coords_all$specificity - 1\noptimal_threshold <- coords_all[which.max(coords_all$youden), ]\n\ncat(\"Optimal Threshold Analysis:\\n\")\ncat(\"Threshold:\", round(optimal_threshold$threshold, 2), \"\\n\")\ncat(\"Sensitivity:\", round(optimal_threshold$sensitivity, 3), \"\\n\")\ncat(\"Specificity:\", round(optimal_threshold$specificity, 3), \"\\n\")\ncat(\"Youden's J:\", round(optimal_threshold$youden, 3), \"\\n\")\n\n# Plot threshold selection\nthreshold_plot <- ggplot(coords_all, aes(x = threshold)) +\n  geom_line(aes(y = sensitivity, color = \"Sensitivity\"), size = 1) +\n  geom_line(aes(y = specificity, color = \"Specificity\"), size = 1) +\n  geom_vline(xintercept = optimal_threshold$threshold, linetype = \"dashed\") +\n  scale_color_manual(values = c(\"blue\", \"red\")) +\n  labs(title = \"Sensitivity and Specificity vs Threshold\",\n       x = \"Biomarker Threshold\", y = \"Rate\", color = \"Metric\") +\n  theme_minimal()\n\nprint(threshold_plot)\n```\n:::\n\n\n\n\n\n\n## Practical Applications in Biostatistics\n\n### 1. Biomarker Validation\n\nWhen developing diagnostic biomarkers:\n- Use ROC analysis to assess discriminative ability\n- Calculate AUC to compare different biomarkers\n- Determine optimal cutoff points balancing sensitivity and specificity\n\n### 2. Risk Prediction Models\n\nIn clinical risk assessment:\n- Logistic regression to model disease probability\n- Confusion matrices to evaluate model performance\n- ROC curves to assess calibration across risk thresholds\n\n### 3. Treatment Response Prediction\n\nFor personalized medicine:\n- Classification models to predict treatment response\n- Performance metrics to validate model utility\n- Threshold optimization for clinical decision-making\n\n::: {.callout-note}\n## Key Takeaways\n\n1. **Confusion matrices** provide a complete picture of classification performance\n2. **Sensitivity and specificity** are fundamental test characteristics\n3. **PPV and NPV** depend on disease prevalence in your population\n4. **ROC curves** visualize the sensitivity-specificity trade-off\n5. **AUC** provides a single metric for overall discriminative ability\n6. **Threshold selection** should consider clinical consequences of false positives vs false negatives\n:::\n\n## Python Implementation\n\nFor those preferring Python, here's equivalent code:\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, classification_report\nfrom sklearn.linear_model import LogisticRegression\n\n# Simulate data\nnp.random.seed(123)\nn = 1000\nage = np.random.normal(55, 12, n)\ncholesterol = np.random.normal(200, 40, n)\nsmoking = np.random.binomial(1, 0.3, n)\n\n# Create outcome\nlog_odds = -5 + 0.05*age + 0.01*cholesterol + 1.2*smoking\nprob_disease = np.exp(log_odds)/(1 + np.exp(log_odds))\nheart_disease = np.random.binomial(1, prob_disease, n)\n\n# Fit logistic regression\nX = np.column_stack([age, cholesterol, smoking])\nmodel = LogisticRegression()\nmodel.fit(X, heart_disease)\n\n# Predictions\ny_pred_proba = model.predict_proba(X)[:, 1]\ny_pred = model.predict(X)\n\n# Confusion matrix\ncm = confusion_matrix(heart_disease, y_pred)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()\n\n# ROC curve\nfpr, tpr, thresholds = roc_curve(heart_disease, y_pred_proba)\nauc_score = roc_auc_score(heart_disease, y_pred_proba)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {auc_score:.3f})')\nplt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend()\nplt.show()\n\n# Classification report\nprint(classification_report(heart_disease, y_pred))\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}